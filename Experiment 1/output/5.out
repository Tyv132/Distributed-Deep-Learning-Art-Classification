The size of the training data set is 76814
The size of the training data set is 76814
Start training
Epoch [1/7], Step [10/1201], Loss: 2.3263
Epoch [1/7], Step [20/1201], Loss: 2.5075
Epoch [1/7], Step [30/1201], Loss: 2.2480
Epoch [1/7], Step [40/1201], Loss: 2.0506
Epoch [1/7], Step [50/1201], Loss: 1.9463
Epoch [1/7], Step [60/1201], Loss: 2.1178
Epoch [1/7], Step [70/1201], Loss: 1.8597
Epoch [1/7], Step [80/1201], Loss: 1.7979
Epoch [1/7], Step [90/1201], Loss: 2.0062
Epoch [1/7], Step [100/1201], Loss: 2.0567
Epoch [1/7], Step [110/1201], Loss: 1.8547
Epoch [1/7], Step [120/1201], Loss: 1.9853
Epoch [1/7], Step [130/1201], Loss: 1.6675
Epoch [1/7], Step [140/1201], Loss: 1.6602
Epoch [1/7], Step [150/1201], Loss: 2.0337
Epoch [1/7], Step [160/1201], Loss: 1.7592
Epoch [1/7], Step [170/1201], Loss: 1.8470
Epoch [1/7], Step [180/1201], Loss: 1.8949
Epoch [1/7], Step [190/1201], Loss: 1.7019
Epoch [1/7], Step [200/1201], Loss: 2.1206
Epoch [1/7], Step [210/1201], Loss: 1.9954
Epoch [1/7], Step [220/1201], Loss: 1.6765
Epoch [1/7], Step [230/1201], Loss: 1.9064
Epoch [1/7], Step [240/1201], Loss: 1.9037
Epoch [1/7], Step [250/1201], Loss: 1.7611
Epoch [1/7], Step [260/1201], Loss: 1.5990
Epoch [1/7], Step [270/1201], Loss: 1.9706
Epoch [1/7], Step [280/1201], Loss: 1.7750
Epoch [1/7], Step [290/1201], Loss: 1.6552
Epoch [1/7], Step [300/1201], Loss: 1.8170
Epoch [1/7], Step [310/1201], Loss: 1.7536
Epoch [1/7], Step [320/1201], Loss: 1.5068
Epoch [1/7], Step [330/1201], Loss: 2.0412
Epoch [1/7], Step [340/1201], Loss: 1.8480
Epoch [1/7], Step [350/1201], Loss: 1.6241
Epoch [1/7], Step [360/1201], Loss: 2.0592
Epoch [1/7], Step [370/1201], Loss: 1.4927
Epoch [1/7], Step [380/1201], Loss: 1.7766
Epoch [1/7], Step [390/1201], Loss: 1.6987
Epoch [1/7], Step [400/1201], Loss: 1.8196
Epoch [1/7], Step [410/1201], Loss: 2.1095
Epoch [1/7], Step [420/1201], Loss: 1.9350
Epoch [1/7], Step [430/1201], Loss: 1.5198
Epoch [1/7], Step [440/1201], Loss: 1.3709
Epoch [1/7], Step [450/1201], Loss: 1.9024
Epoch [1/7], Step [460/1201], Loss: 1.4229
Epoch [1/7], Step [470/1201], Loss: 1.6034
Epoch [1/7], Step [480/1201], Loss: 1.8020
Epoch [1/7], Step [490/1201], Loss: 1.7001
Epoch [1/7], Step [500/1201], Loss: 1.7533
Epoch [1/7], Step [510/1201], Loss: 1.8118
Epoch [1/7], Step [520/1201], Loss: 1.5004
Epoch [1/7], Step [530/1201], Loss: 1.5275
Epoch [1/7], Step [540/1201], Loss: 1.9060
Epoch [1/7], Step [550/1201], Loss: 1.9336
Epoch [1/7], Step [560/1201], Loss: 1.7465
Epoch [1/7], Step [570/1201], Loss: 1.3144
Epoch [1/7], Step [580/1201], Loss: 2.0879
Epoch [1/7], Step [590/1201], Loss: 1.9450
Epoch [1/7], Step [600/1201], Loss: 1.5194
Epoch [1/7], Step [610/1201], Loss: 1.7621
Epoch [1/7], Step [620/1201], Loss: 1.6072
Epoch [1/7], Step [630/1201], Loss: 1.9892
Epoch [1/7], Step [640/1201], Loss: 1.5139
Epoch [1/7], Step [650/1201], Loss: 1.6857
Epoch [1/7], Step [660/1201], Loss: 1.9804
Epoch [1/7], Step [670/1201], Loss: 1.8169
Epoch [1/7], Step [680/1201], Loss: 1.7651
Epoch [1/7], Step [690/1201], Loss: 1.7537
Epoch [1/7], Step [700/1201], Loss: 1.9062
Epoch [1/7], Step [710/1201], Loss: 1.8740
Epoch [1/7], Step [720/1201], Loss: 1.4736
Epoch [1/7], Step [730/1201], Loss: 1.6782
Epoch [1/7], Step [740/1201], Loss: 2.0632
Epoch [1/7], Step [750/1201], Loss: 1.4941
Epoch [1/7], Step [760/1201], Loss: 1.7640
Epoch [1/7], Step [770/1201], Loss: 1.8385
Epoch [1/7], Step [780/1201], Loss: 1.8194
Epoch [1/7], Step [790/1201], Loss: 1.7618
Epoch [1/7], Step [800/1201], Loss: 1.6737
Epoch [1/7], Step [810/1201], Loss: 1.3931
Epoch [1/7], Step [820/1201], Loss: 1.7023
Epoch [1/7], Step [830/1201], Loss: 1.6839
Epoch [1/7], Step [840/1201], Loss: 1.6670
Epoch [1/7], Step [850/1201], Loss: 1.8295
Epoch [1/7], Step [860/1201], Loss: 1.6486
Epoch [1/7], Step [870/1201], Loss: 1.6182
Epoch [1/7], Step [880/1201], Loss: 1.4389
Epoch [1/7], Step [890/1201], Loss: 1.9451
Epoch [1/7], Step [900/1201], Loss: 1.6082
Epoch [1/7], Step [910/1201], Loss: 1.3682
Epoch [1/7], Step [920/1201], Loss: 1.8820
Epoch [1/7], Step [930/1201], Loss: 1.6555
Epoch [1/7], Step [940/1201], Loss: 1.4953
Epoch [1/7], Step [950/1201], Loss: 1.7150
Epoch [1/7], Step [960/1201], Loss: 1.7753
Epoch [1/7], Step [970/1201], Loss: 1.5449
Epoch [1/7], Step [980/1201], Loss: 1.7630
Epoch [1/7], Step [990/1201], Loss: 1.5235
Epoch [1/7], Step [1000/1201], Loss: 1.6670
Epoch [1/7], Step [1010/1201], Loss: 1.1264
Epoch [1/7], Step [1020/1201], Loss: 1.9507
Epoch [1/7], Step [1030/1201], Loss: 1.3300
Epoch [1/7], Step [1040/1201], Loss: 1.5700
Epoch [1/7], Step [1050/1201], Loss: 1.4649
Epoch [1/7], Step [1060/1201], Loss: 1.5799
Epoch [1/7], Step [1070/1201], Loss: 1.5504
Epoch [1/7], Step [1080/1201], Loss: 1.8695
Epoch [1/7], Step [1090/1201], Loss: 1.6165
Epoch [1/7], Step [1100/1201], Loss: 1.8647
Epoch [1/7], Step [1110/1201], Loss: 1.6667
Epoch [1/7], Step [1120/1201], Loss: 1.7509
Epoch [1/7], Step [1130/1201], Loss: 1.3937
Epoch [1/7], Step [1140/1201], Loss: 1.1130
Epoch [1/7], Step [1150/1201], Loss: 1.9197
Epoch [1/7], Step [1160/1201], Loss: 1.7597
Epoch [1/7], Step [1170/1201], Loss: 1.4852
Epoch [1/7], Step [1180/1201], Loss: 1.5740
Epoch [1/7], Step [1190/1201], Loss: 1.4737
Epoch [1/7], Step [1200/1201], Loss: 1.6665
Total time for epoch 1/7 = 1619.094817 seconds
Start validation
Validation accuracy is 23.59129257369024%
Start training
Epoch [2/7], Step [10/1201], Loss: 1.7411
Epoch [2/7], Step [20/1201], Loss: 1.8422
Epoch [2/7], Step [30/1201], Loss: 1.5171
Epoch [2/7], Step [40/1201], Loss: 2.0781
Epoch [2/7], Step [50/1201], Loss: 1.2168
Epoch [2/7], Step [60/1201], Loss: 1.8613
Epoch [2/7], Step [70/1201], Loss: 1.5446
Epoch [2/7], Step [80/1201], Loss: 1.1881
Epoch [2/7], Step [90/1201], Loss: 1.6875
Epoch [2/7], Step [100/1201], Loss: 1.5990
Epoch [2/7], Step [110/1201], Loss: 1.6283
Epoch [2/7], Step [120/1201], Loss: 1.6837
Epoch [2/7], Step [130/1201], Loss: 1.3920
Epoch [2/7], Step [140/1201], Loss: 1.3134
Epoch [2/7], Step [150/1201], Loss: 1.8755
Epoch [2/7], Step [160/1201], Loss: 1.5037
Epoch [2/7], Step [170/1201], Loss: 1.7836
Epoch [2/7], Step [180/1201], Loss: 1.5052
Epoch [2/7], Step [190/1201], Loss: 1.2806
Epoch [2/7], Step [200/1201], Loss: 1.5147
Epoch [2/7], Step [210/1201], Loss: 1.6470
Epoch [2/7], Step [220/1201], Loss: 1.5023
Epoch [2/7], Step [230/1201], Loss: 1.5455
Epoch [2/7], Step [240/1201], Loss: 1.3609
Epoch [2/7], Step [250/1201], Loss: 1.7546
Epoch [2/7], Step [260/1201], Loss: 1.2810
Epoch [2/7], Step [270/1201], Loss: 1.5609
Epoch [2/7], Step [280/1201], Loss: 1.7659
Epoch [2/7], Step [290/1201], Loss: 1.4679
Epoch [2/7], Step [300/1201], Loss: 1.6571
Epoch [2/7], Step [310/1201], Loss: 1.5354
Epoch [2/7], Step [320/1201], Loss: 1.1435
Epoch [2/7], Step [330/1201], Loss: 1.9964
Epoch [2/7], Step [340/1201], Loss: 1.7144
Epoch [2/7], Step [350/1201], Loss: 1.2946
Epoch [2/7], Step [360/1201], Loss: 1.7650
Epoch [2/7], Step [370/1201], Loss: 1.2282
Epoch [2/7], Step [380/1201], Loss: 1.7430
Epoch [2/7], Step [390/1201], Loss: 1.5423
Epoch [2/7], Step [400/1201], Loss: 1.6633
Epoch [2/7], Step [410/1201], Loss: 1.9997
Epoch [2/7], Step [420/1201], Loss: 1.4469
Epoch [2/7], Step [430/1201], Loss: 1.2053
Epoch [2/7], Step [440/1201], Loss: 1.2063
Epoch [2/7], Step [450/1201], Loss: 1.6868
Epoch [2/7], Step [460/1201], Loss: 1.2104
Epoch [2/7], Step [470/1201], Loss: 1.3658
Epoch [2/7], Step [480/1201], Loss: 1.6770
Epoch [2/7], Step [490/1201], Loss: 1.5257
Epoch [2/7], Step [500/1201], Loss: 1.4777
Epoch [2/7], Step [510/1201], Loss: 1.5610
Epoch [2/7], Step [520/1201], Loss: 1.2919
Epoch [2/7], Step [530/1201], Loss: 1.3538
Epoch [2/7], Step [540/1201], Loss: 1.5355
Epoch [2/7], Step [550/1201], Loss: 1.5757
Epoch [2/7], Step [560/1201], Loss: 1.4063
Epoch [2/7], Step [570/1201], Loss: 1.2922
Epoch [2/7], Step [580/1201], Loss: 1.5861
Epoch [2/7], Step [590/1201], Loss: 1.7524
Epoch [2/7], Step [600/1201], Loss: 1.3989
Epoch [2/7], Step [610/1201], Loss: 1.5462
Epoch [2/7], Step [620/1201], Loss: 1.5304
Epoch [2/7], Step [630/1201], Loss: 1.8636
Epoch [2/7], Step [640/1201], Loss: 1.3508
Epoch [2/7], Step [650/1201], Loss: 1.5897
Epoch [2/7], Step [660/1201], Loss: 1.7559
Epoch [2/7], Step [670/1201], Loss: 1.6382
Epoch [2/7], Step [680/1201], Loss: 1.5888
Epoch [2/7], Step [690/1201], Loss: 1.5305
Epoch [2/7], Step [700/1201], Loss: 1.5868
Epoch [2/7], Step [710/1201], Loss: 1.6256
Epoch [2/7], Step [720/1201], Loss: 1.2783
Epoch [2/7], Step [730/1201], Loss: 1.3134
Epoch [2/7], Step [740/1201], Loss: 1.7340
Epoch [2/7], Step [750/1201], Loss: 1.3208
Epoch [2/7], Step [760/1201], Loss: 1.3959
Epoch [2/7], Step [770/1201], Loss: 1.6397
Epoch [2/7], Step [780/1201], Loss: 1.7691
Epoch [2/7], Step [790/1201], Loss: 1.4742
Epoch [2/7], Step [800/1201], Loss: 1.4333
Epoch [2/7], Step [810/1201], Loss: 1.1471
Epoch [2/7], Step [820/1201], Loss: 1.7249
Epoch [2/7], Step [830/1201], Loss: 1.5026
Epoch [2/7], Step [840/1201], Loss: 1.4020
Epoch [2/7], Step [850/1201], Loss: 1.7889
Epoch [2/7], Step [860/1201], Loss: 1.5921
Epoch [2/7], Step [870/1201], Loss: 1.3472
Epoch [2/7], Step [880/1201], Loss: 1.1977
Epoch [2/7], Step [890/1201], Loss: 1.7173
Epoch [2/7], Step [900/1201], Loss: 1.4251
Epoch [2/7], Step [910/1201], Loss: 1.2118
Epoch [2/7], Step [920/1201], Loss: 1.7089
Epoch [2/7], Step [930/1201], Loss: 1.6089
Epoch [2/7], Step [940/1201], Loss: 1.2667
Epoch [2/7], Step [950/1201], Loss: 1.5155
Epoch [2/7], Step [960/1201], Loss: 1.5898
Epoch [2/7], Step [970/1201], Loss: 1.2780
Epoch [2/7], Step [980/1201], Loss: 1.4160
Epoch [2/7], Step [990/1201], Loss: 1.3585
Epoch [2/7], Step [1000/1201], Loss: 1.3633
Epoch [2/7], Step [1010/1201], Loss: 0.9493
Epoch [2/7], Step [1020/1201], Loss: 1.5999
Epoch [2/7], Step [1030/1201], Loss: 1.2809
Epoch [2/7], Step [1040/1201], Loss: 1.3436
Epoch [2/7], Step [1050/1201], Loss: 1.1692
Epoch [2/7], Step [1060/1201], Loss: 1.3845
Epoch [2/7], Step [1070/1201], Loss: 1.5077
Epoch [2/7], Step [1080/1201], Loss: 1.8073
Epoch [2/7], Step [1090/1201], Loss: 1.5128
Epoch [2/7], Step [1100/1201], Loss: 1.6944
Epoch [2/7], Step [1110/1201], Loss: 1.4949
Epoch [2/7], Step [1120/1201], Loss: 1.6576
Epoch [2/7], Step [1130/1201], Loss: 1.2643
Epoch [2/7], Step [1140/1201], Loss: 0.9849
Epoch [2/7], Step [1150/1201], Loss: 1.7061
Epoch [2/7], Step [1160/1201], Loss: 1.5121
Epoch [2/7], Step [1170/1201], Loss: 1.2559
Epoch [2/7], Step [1180/1201], Loss: 1.4740
Epoch [2/7], Step [1190/1201], Loss: 1.3113
Epoch [2/7], Step [1200/1201], Loss: 1.5115
Total time for epoch 2/7 = 1458.578397 seconds
The average of the epoch train time so far is 1458.578397
The stdev of the epoch train time so far is 0.0
Start validation
Validation accuracy is 24.43495469221956%
Start training
Epoch [3/7], Step [10/1201], Loss: 1.6051
Epoch [3/7], Step [20/1201], Loss: 1.4581
Epoch [3/7], Step [30/1201], Loss: 1.4215
Epoch [3/7], Step [40/1201], Loss: 1.6731
Epoch [3/7], Step [50/1201], Loss: 1.0246
Epoch [3/7], Step [60/1201], Loss: 1.7076
Epoch [3/7], Step [70/1201], Loss: 1.2747
Epoch [3/7], Step [80/1201], Loss: 1.0199
Epoch [3/7], Step [90/1201], Loss: 1.4167
Epoch [3/7], Step [100/1201], Loss: 1.5375
Epoch [3/7], Step [110/1201], Loss: 1.4513
Epoch [3/7], Step [120/1201], Loss: 1.3432
Epoch [3/7], Step [130/1201], Loss: 1.1785
Epoch [3/7], Step [140/1201], Loss: 1.1263
Epoch [3/7], Step [150/1201], Loss: 1.6757
Epoch [3/7], Step [160/1201], Loss: 1.2327
Epoch [3/7], Step [170/1201], Loss: 1.5398
Epoch [3/7], Step [180/1201], Loss: 1.3284
Epoch [3/7], Step [190/1201], Loss: 1.0416
Epoch [3/7], Step [200/1201], Loss: 1.2871
Epoch [3/7], Step [210/1201], Loss: 1.4963
Epoch [3/7], Step [220/1201], Loss: 1.4056
Epoch [3/7], Step [230/1201], Loss: 1.4090
Epoch [3/7], Step [240/1201], Loss: 1.2444
Epoch [3/7], Step [250/1201], Loss: 1.7256
Epoch [3/7], Step [260/1201], Loss: 1.1218
Epoch [3/7], Step [270/1201], Loss: 1.3527
Epoch [3/7], Step [280/1201], Loss: 1.5549
Epoch [3/7], Step [290/1201], Loss: 1.1690
Epoch [3/7], Step [300/1201], Loss: 1.6057
Epoch [3/7], Step [310/1201], Loss: 1.2880
Epoch [3/7], Step [320/1201], Loss: 0.9507
Epoch [3/7], Step [330/1201], Loss: 1.7597
Epoch [3/7], Step [340/1201], Loss: 1.6523
Epoch [3/7], Step [350/1201], Loss: 1.2835
Epoch [3/7], Step [360/1201], Loss: 1.6214
Epoch [3/7], Step [370/1201], Loss: 1.0244
Epoch [3/7], Step [380/1201], Loss: 1.5314
Epoch [3/7], Step [390/1201], Loss: 1.4524
Epoch [3/7], Step [400/1201], Loss: 1.5656
Epoch [3/7], Step [410/1201], Loss: 1.9042
Epoch [3/7], Step [420/1201], Loss: 1.4604
Epoch [3/7], Step [430/1201], Loss: 0.9594
Epoch [3/7], Step [440/1201], Loss: 1.0378
Epoch [3/7], Step [450/1201], Loss: 1.5970
Epoch [3/7], Step [460/1201], Loss: 1.1925
Epoch [3/7], Step [470/1201], Loss: 1.4491
Epoch [3/7], Step [480/1201], Loss: 1.5291
Epoch [3/7], Step [490/1201], Loss: 1.3261
Epoch [3/7], Step [500/1201], Loss: 1.3814
Epoch [3/7], Step [510/1201], Loss: 1.4048
Epoch [3/7], Step [520/1201], Loss: 1.2076
Epoch [3/7], Step [530/1201], Loss: 1.2132
Epoch [3/7], Step [540/1201], Loss: 1.5148
Epoch [3/7], Step [550/1201], Loss: 1.2468
Epoch [3/7], Step [560/1201], Loss: 1.2944
Epoch [3/7], Step [570/1201], Loss: 1.2063
Epoch [3/7], Step [580/1201], Loss: 1.3337
Epoch [3/7], Step [590/1201], Loss: 1.5520
Epoch [3/7], Step [600/1201], Loss: 1.2593
Epoch [3/7], Step [610/1201], Loss: 1.4030
Epoch [3/7], Step [620/1201], Loss: 1.2533
Epoch [3/7], Step [630/1201], Loss: 1.8090
Epoch [3/7], Step [640/1201], Loss: 1.2209
Epoch [3/7], Step [650/1201], Loss: 1.4617
Epoch [3/7], Step [660/1201], Loss: 1.6342
Epoch [3/7], Step [670/1201], Loss: 1.4735
Epoch [3/7], Step [680/1201], Loss: 1.3543
Epoch [3/7], Step [690/1201], Loss: 1.1757
Epoch [3/7], Step [700/1201], Loss: 1.4526
Epoch [3/7], Step [710/1201], Loss: 1.5189
Epoch [3/7], Step [720/1201], Loss: 1.2295
Epoch [3/7], Step [730/1201], Loss: 1.1125
Epoch [3/7], Step [740/1201], Loss: 1.5041
Epoch [3/7], Step [750/1201], Loss: 1.3041
Epoch [3/7], Step [760/1201], Loss: 1.1215
Epoch [3/7], Step [770/1201], Loss: 1.4522
Epoch [3/7], Step [780/1201], Loss: 1.6393
Epoch [3/7], Step [790/1201], Loss: 1.3895
Epoch [3/7], Step [800/1201], Loss: 1.2997
Epoch [3/7], Step [810/1201], Loss: 1.0115
Epoch [3/7], Step [820/1201], Loss: 1.5641
Epoch [3/7], Step [830/1201], Loss: 1.4142
Epoch [3/7], Step [840/1201], Loss: 1.1831
Epoch [3/7], Step [850/1201], Loss: 1.7046
Epoch [3/7], Step [860/1201], Loss: 1.4829
Epoch [3/7], Step [870/1201], Loss: 1.3316
Epoch [3/7], Step [880/1201], Loss: 1.1813
Epoch [3/7], Step [890/1201], Loss: 1.6573
Epoch [3/7], Step [900/1201], Loss: 1.2471
Epoch [3/7], Step [910/1201], Loss: 1.0820
Epoch [3/7], Step [920/1201], Loss: 1.4970
Epoch [3/7], Step [930/1201], Loss: 1.6243
Epoch [3/7], Step [940/1201], Loss: 1.1136
Epoch [3/7], Step [950/1201], Loss: 1.5208
Epoch [3/7], Step [960/1201], Loss: 1.5647
Epoch [3/7], Step [970/1201], Loss: 1.1110
Epoch [3/7], Step [980/1201], Loss: 1.2481
Epoch [3/7], Step [990/1201], Loss: 1.1817
Epoch [3/7], Step [1000/1201], Loss: 1.3451
Epoch [3/7], Step [1010/1201], Loss: 0.7798
Epoch [3/7], Step [1020/1201], Loss: 1.5348
Epoch [3/7], Step [1030/1201], Loss: 1.1010
Epoch [3/7], Step [1040/1201], Loss: 1.2044
Epoch [3/7], Step [1050/1201], Loss: 1.0510
Epoch [3/7], Step [1060/1201], Loss: 1.3289
Epoch [3/7], Step [1070/1201], Loss: 1.3265
Epoch [3/7], Step [1080/1201], Loss: 1.7191
Epoch [3/7], Step [1090/1201], Loss: 1.3241
Epoch [3/7], Step [1100/1201], Loss: 1.4992
Epoch [3/7], Step [1110/1201], Loss: 1.2748
Epoch [3/7], Step [1120/1201], Loss: 1.5471
Epoch [3/7], Step [1130/1201], Loss: 1.1013
Epoch [3/7], Step [1140/1201], Loss: 0.9900
Epoch [3/7], Step [1150/1201], Loss: 1.5923
Epoch [3/7], Step [1160/1201], Loss: 1.3766
Epoch [3/7], Step [1170/1201], Loss: 1.1693
Epoch [3/7], Step [1180/1201], Loss: 1.4256
Epoch [3/7], Step [1190/1201], Loss: 1.1451
Epoch [3/7], Step [1200/1201], Loss: 1.3217
Total time for epoch 3/7 = 1338.345917 seconds
The average of the epoch train time so far is 1398.462157
The stdev of the epoch train time so far is 60.11623999999995
Start validation
Validation accuracy is 26.736798250182275%
Start training
Epoch [4/7], Step [10/1201], Loss: 1.4207
Epoch [4/7], Step [20/1201], Loss: 1.2707
Epoch [4/7], Step [30/1201], Loss: 1.3779
Epoch [4/7], Step [40/1201], Loss: 1.4211
Epoch [4/7], Step [50/1201], Loss: 0.8542
Epoch [4/7], Step [60/1201], Loss: 1.5850
Epoch [4/7], Step [70/1201], Loss: 1.1084
Epoch [4/7], Step [80/1201], Loss: 0.9208
Epoch [4/7], Step [90/1201], Loss: 1.2852
Epoch [4/7], Step [100/1201], Loss: 1.3719
Epoch [4/7], Step [110/1201], Loss: 1.3497
Epoch [4/7], Step [120/1201], Loss: 1.2235
Epoch [4/7], Step [130/1201], Loss: 1.0392
Epoch [4/7], Step [140/1201], Loss: 0.9708
Epoch [4/7], Step [150/1201], Loss: 1.5406
Epoch [4/7], Step [160/1201], Loss: 1.1502
Epoch [4/7], Step [170/1201], Loss: 1.3711
Epoch [4/7], Step [180/1201], Loss: 1.2686
Epoch [4/7], Step [190/1201], Loss: 0.8900
Epoch [4/7], Step [200/1201], Loss: 1.0042
Epoch [4/7], Step [210/1201], Loss: 1.2402
Epoch [4/7], Step [220/1201], Loss: 1.2226
Epoch [4/7], Step [230/1201], Loss: 1.3365
Epoch [4/7], Step [240/1201], Loss: 1.1690
Epoch [4/7], Step [250/1201], Loss: 1.5021
Epoch [4/7], Step [260/1201], Loss: 1.0329
Epoch [4/7], Step [270/1201], Loss: 1.3280
Epoch [4/7], Step [280/1201], Loss: 1.4563
Epoch [4/7], Step [290/1201], Loss: 0.9981
Epoch [4/7], Step [300/1201], Loss: 1.4753
Epoch [4/7], Step [310/1201], Loss: 1.2192
Epoch [4/7], Step [320/1201], Loss: 0.7771
Epoch [4/7], Step [330/1201], Loss: 1.7501
Epoch [4/7], Step [340/1201], Loss: 1.4595
Epoch [4/7], Step [350/1201], Loss: 1.0911
Epoch [4/7], Step [360/1201], Loss: 1.5877
Epoch [4/7], Step [370/1201], Loss: 1.0099
Epoch [4/7], Step [380/1201], Loss: 1.2765
Epoch [4/7], Step [390/1201], Loss: 1.4017
Epoch [4/7], Step [400/1201], Loss: 1.4792
Epoch [4/7], Step [410/1201], Loss: 1.8462
Epoch [4/7], Step [420/1201], Loss: 1.3927
Epoch [4/7], Step [430/1201], Loss: 0.9680
Epoch [4/7], Step [440/1201], Loss: 0.9421
Epoch [4/7], Step [450/1201], Loss: 1.3754
Epoch [4/7], Step [460/1201], Loss: 1.1604
Epoch [4/7], Step [470/1201], Loss: 1.4800
Epoch [4/7], Step [480/1201], Loss: 1.3031
Epoch [4/7], Step [490/1201], Loss: 1.3088
Epoch [4/7], Step [500/1201], Loss: 1.3326
Epoch [4/7], Step [510/1201], Loss: 1.2895
Epoch [4/7], Step [520/1201], Loss: 1.1362
Epoch [4/7], Step [530/1201], Loss: 1.0911
Epoch [4/7], Step [540/1201], Loss: 1.4471
Epoch [4/7], Step [550/1201], Loss: 1.1984
Epoch [4/7], Step [560/1201], Loss: 1.1579
Epoch [4/7], Step [570/1201], Loss: 1.1422
Epoch [4/7], Step [580/1201], Loss: 1.1942
Epoch [4/7], Step [590/1201], Loss: 1.3495
Epoch [4/7], Step [600/1201], Loss: 1.1245
Epoch [4/7], Step [610/1201], Loss: 1.2871
Epoch [4/7], Step [620/1201], Loss: 1.0257
Epoch [4/7], Step [630/1201], Loss: 1.5966
Epoch [4/7], Step [640/1201], Loss: 1.0869
Epoch [4/7], Step [650/1201], Loss: 1.3473
Epoch [4/7], Step [660/1201], Loss: 1.5282
Epoch [4/7], Step [670/1201], Loss: 1.2852
Epoch [4/7], Step [680/1201], Loss: 1.1486
Epoch [4/7], Step [690/1201], Loss: 1.1692
Epoch [4/7], Step [700/1201], Loss: 1.3532
Epoch [4/7], Step [710/1201], Loss: 1.3754
Epoch [4/7], Step [720/1201], Loss: 1.1542
Epoch [4/7], Step [730/1201], Loss: 1.0094
Epoch [4/7], Step [740/1201], Loss: 1.5150
Epoch [4/7], Step [750/1201], Loss: 1.2501
Epoch [4/7], Step [760/1201], Loss: 1.1402
Epoch [4/7], Step [770/1201], Loss: 1.3653
Epoch [4/7], Step [780/1201], Loss: 1.4608
Epoch [4/7], Step [790/1201], Loss: 1.4074
Epoch [4/7], Step [800/1201], Loss: 1.2862
Epoch [4/7], Step [810/1201], Loss: 1.0293
Epoch [4/7], Step [820/1201], Loss: 1.2475
Epoch [4/7], Step [830/1201], Loss: 1.3678
Epoch [4/7], Step [840/1201], Loss: 1.0305
Epoch [4/7], Step [850/1201], Loss: 1.4936
Epoch [4/7], Step [860/1201], Loss: 1.5105
Epoch [4/7], Step [870/1201], Loss: 1.3643
Epoch [4/7], Step [880/1201], Loss: 1.1423
Epoch [4/7], Step [890/1201], Loss: 1.5549
Epoch [4/7], Step [900/1201], Loss: 1.1769
Epoch [4/7], Step [910/1201], Loss: 0.9975
Epoch [4/7], Step [920/1201], Loss: 1.3345
Epoch [4/7], Step [930/1201], Loss: 1.5861
Epoch [4/7], Step [940/1201], Loss: 0.9756
Epoch [4/7], Step [950/1201], Loss: 1.3708
Epoch [4/7], Step [960/1201], Loss: 1.3256
Epoch [4/7], Step [970/1201], Loss: 1.0600
Epoch [4/7], Step [980/1201], Loss: 1.0956
Epoch [4/7], Step [990/1201], Loss: 1.1022
Epoch [4/7], Step [1000/1201], Loss: 1.3947
Epoch [4/7], Step [1010/1201], Loss: 0.6414
Epoch [4/7], Step [1020/1201], Loss: 1.3727
Epoch [4/7], Step [1030/1201], Loss: 1.0630
Epoch [4/7], Step [1040/1201], Loss: 1.1797
Epoch [4/7], Step [1050/1201], Loss: 0.9611
Epoch [4/7], Step [1060/1201], Loss: 1.2867
Epoch [4/7], Step [1070/1201], Loss: 1.2096
Epoch [4/7], Step [1080/1201], Loss: 1.5042
Epoch [4/7], Step [1090/1201], Loss: 1.2213
Epoch [4/7], Step [1100/1201], Loss: 1.3588
Epoch [4/7], Step [1110/1201], Loss: 1.1738
Epoch [4/7], Step [1120/1201], Loss: 1.5358
Epoch [4/7], Step [1130/1201], Loss: 1.0410
Epoch [4/7], Step [1140/1201], Loss: 0.8606
Epoch [4/7], Step [1150/1201], Loss: 1.4153
Epoch [4/7], Step [1160/1201], Loss: 1.4509
Epoch [4/7], Step [1170/1201], Loss: 0.9688
Epoch [4/7], Step [1180/1201], Loss: 1.1947
Epoch [4/7], Step [1190/1201], Loss: 1.1107
Epoch [4/7], Step [1200/1201], Loss: 1.2760
Total time for epoch 4/7 = 1369.877912 seconds
The average of the epoch train time so far is 1388.9340753333333
The stdev of the epoch train time so far is 50.90065705193208
Start validation
Validation accuracy is 27.278408499114676%
Start training
Epoch [5/7], Step [10/1201], Loss: 1.3729
Epoch [5/7], Step [20/1201], Loss: 1.1402
Epoch [5/7], Step [30/1201], Loss: 1.2904
Epoch [5/7], Step [40/1201], Loss: 1.3160
Epoch [5/7], Step [50/1201], Loss: 0.9086
Epoch [5/7], Step [60/1201], Loss: 1.4302
Epoch [5/7], Step [70/1201], Loss: 0.9814
Epoch [5/7], Step [80/1201], Loss: 0.8984
Epoch [5/7], Step [90/1201], Loss: 1.1808
Epoch [5/7], Step [100/1201], Loss: 1.3133
Epoch [5/7], Step [110/1201], Loss: 1.1597
Epoch [5/7], Step [120/1201], Loss: 1.0760
Epoch [5/7], Step [130/1201], Loss: 1.0300
Epoch [5/7], Step [140/1201], Loss: 0.9262
Epoch [5/7], Step [150/1201], Loss: 1.5745
Epoch [5/7], Step [160/1201], Loss: 1.0528
Epoch [5/7], Step [170/1201], Loss: 1.3573
Epoch [5/7], Step [180/1201], Loss: 1.0820
Epoch [5/7], Step [190/1201], Loss: 0.8465
Epoch [5/7], Step [200/1201], Loss: 0.9103
Epoch [5/7], Step [210/1201], Loss: 1.1143
Epoch [5/7], Step [220/1201], Loss: 1.0197
Epoch [5/7], Step [230/1201], Loss: 1.2484
Epoch [5/7], Step [240/1201], Loss: 1.2029
Epoch [5/7], Step [250/1201], Loss: 1.3988
Epoch [5/7], Step [260/1201], Loss: 1.0406
Epoch [5/7], Step [270/1201], Loss: 1.2217
Epoch [5/7], Step [280/1201], Loss: 1.2480
Epoch [5/7], Step [290/1201], Loss: 0.9353
Epoch [5/7], Step [300/1201], Loss: 1.4411
Epoch [5/7], Step [310/1201], Loss: 1.2079
Epoch [5/7], Step [320/1201], Loss: 0.6890
Epoch [5/7], Step [330/1201], Loss: 1.6842
Epoch [5/7], Step [340/1201], Loss: 1.4070
Epoch [5/7], Step [350/1201], Loss: 0.9856
Epoch [5/7], Step [360/1201], Loss: 1.5837
Epoch [5/7], Step [370/1201], Loss: 0.9386
Epoch [5/7], Step [380/1201], Loss: 1.1266
Epoch [5/7], Step [390/1201], Loss: 1.3537
Epoch [5/7], Step [400/1201], Loss: 1.3528
Epoch [5/7], Step [410/1201], Loss: 1.8075
Epoch [5/7], Step [420/1201], Loss: 1.2795
Epoch [5/7], Step [430/1201], Loss: 0.9728
Epoch [5/7], Step [440/1201], Loss: 0.8814
Epoch [5/7], Step [450/1201], Loss: 1.2554
Epoch [5/7], Step [460/1201], Loss: 1.1344
Epoch [5/7], Step [470/1201], Loss: 1.4370
Epoch [5/7], Step [480/1201], Loss: 1.2546
Epoch [5/7], Step [490/1201], Loss: 1.2341
Epoch [5/7], Step [500/1201], Loss: 1.3337
Epoch [5/7], Step [510/1201], Loss: 1.2625
Epoch [5/7], Step [520/1201], Loss: 1.0475
Epoch [5/7], Step [530/1201], Loss: 1.0184
Epoch [5/7], Step [540/1201], Loss: 1.3425
Epoch [5/7], Step [550/1201], Loss: 1.0379
Epoch [5/7], Step [560/1201], Loss: 1.0544
Epoch [5/7], Step [570/1201], Loss: 1.0498
Epoch [5/7], Step [580/1201], Loss: 1.0782
Epoch [5/7], Step [590/1201], Loss: 1.2914
Epoch [5/7], Step [600/1201], Loss: 1.0430
Epoch [5/7], Step [610/1201], Loss: 1.1576
Epoch [5/7], Step [620/1201], Loss: 0.9341
Epoch [5/7], Step [630/1201], Loss: 1.4898
Epoch [5/7], Step [640/1201], Loss: 1.0472
Epoch [5/7], Step [650/1201], Loss: 1.3024
Epoch [5/7], Step [660/1201], Loss: 1.4080
Epoch [5/7], Step [670/1201], Loss: 1.2222
Epoch [5/7], Step [680/1201], Loss: 1.1276
Epoch [5/7], Step [690/1201], Loss: 1.0658
Epoch [5/7], Step [700/1201], Loss: 1.2597
Epoch [5/7], Step [710/1201], Loss: 1.3426
Epoch [5/7], Step [720/1201], Loss: 1.0397
Epoch [5/7], Step [730/1201], Loss: 1.0164
Epoch [5/7], Step [740/1201], Loss: 1.3798
Epoch [5/7], Step [750/1201], Loss: 1.1859
Epoch [5/7], Step [760/1201], Loss: 0.9078
Epoch [5/7], Step [770/1201], Loss: 1.1604
Epoch [5/7], Step [780/1201], Loss: 1.3880
Epoch [5/7], Step [790/1201], Loss: 1.3771
Epoch [5/7], Step [800/1201], Loss: 1.1570
Epoch [5/7], Step [810/1201], Loss: 1.0324
Epoch [5/7], Step [820/1201], Loss: 1.2932
Epoch [5/7], Step [830/1201], Loss: 1.1639
Epoch [5/7], Step [840/1201], Loss: 0.9699
Epoch [5/7], Step [850/1201], Loss: 1.4554
Epoch [5/7], Step [860/1201], Loss: 1.2758
Epoch [5/7], Step [870/1201], Loss: 1.3881
Epoch [5/7], Step [880/1201], Loss: 1.0633
Epoch [5/7], Step [890/1201], Loss: 1.5827
Epoch [5/7], Step [900/1201], Loss: 1.0993
Epoch [5/7], Step [910/1201], Loss: 0.9964
Epoch [5/7], Step [920/1201], Loss: 1.1664
Epoch [5/7], Step [930/1201], Loss: 1.4125
Epoch [5/7], Step [940/1201], Loss: 0.9012
Epoch [5/7], Step [950/1201], Loss: 1.3133
Epoch [5/7], Step [960/1201], Loss: 1.1156
Epoch [5/7], Step [970/1201], Loss: 0.9751
Epoch [5/7], Step [980/1201], Loss: 1.0562
Epoch [5/7], Step [990/1201], Loss: 1.0083
Epoch [5/7], Step [1000/1201], Loss: 1.1604
Epoch [5/7], Step [1010/1201], Loss: 0.5971
Epoch [5/7], Step [1020/1201], Loss: 1.2650
Epoch [5/7], Step [1030/1201], Loss: 0.8591
Epoch [5/7], Step [1040/1201], Loss: 1.1492
Epoch [5/7], Step [1050/1201], Loss: 0.8830
Epoch [5/7], Step [1060/1201], Loss: 1.2404
Epoch [5/7], Step [1070/1201], Loss: 1.0733
Epoch [5/7], Step [1080/1201], Loss: 1.4005
Epoch [5/7], Step [1090/1201], Loss: 1.0133
Epoch [5/7], Step [1100/1201], Loss: 1.2611
Epoch [5/7], Step [1110/1201], Loss: 1.0786
Epoch [5/7], Step [1120/1201], Loss: 1.3684
Epoch [5/7], Step [1130/1201], Loss: 0.9870
Epoch [5/7], Step [1140/1201], Loss: 0.8071
Epoch [5/7], Step [1150/1201], Loss: 1.2672
Epoch [5/7], Step [1160/1201], Loss: 1.3215
Epoch [5/7], Step [1170/1201], Loss: 0.9001
Epoch [5/7], Step [1180/1201], Loss: 1.0771
Epoch [5/7], Step [1190/1201], Loss: 1.1375
Epoch [5/7], Step [1200/1201], Loss: 1.1507
Total time for epoch 5/7 = 1373.384215 seconds
The average of the epoch train time so far is 1385.04661025
The stdev of the epoch train time so far is 44.59254220787608
Start validation
Validation accuracy is 26.72638266847203%
Start training
Epoch [6/7], Step [10/1201], Loss: 1.3452
Epoch [6/7], Step [20/1201], Loss: 1.0017
Epoch [6/7], Step [30/1201], Loss: 1.0932
Epoch [6/7], Step [40/1201], Loss: 1.1361
Epoch [6/7], Step [50/1201], Loss: 0.7670
Epoch [6/7], Step [60/1201], Loss: 1.2440
Epoch [6/7], Step [70/1201], Loss: 0.8892
Epoch [6/7], Step [80/1201], Loss: 0.8349
Epoch [6/7], Step [90/1201], Loss: 1.0045
Epoch [6/7], Step [100/1201], Loss: 1.2080
Epoch [6/7], Step [110/1201], Loss: 1.0386
Epoch [6/7], Step [120/1201], Loss: 1.0352
Epoch [6/7], Step [130/1201], Loss: 0.9330
Epoch [6/7], Step [140/1201], Loss: 0.8674
Epoch [6/7], Step [150/1201], Loss: 1.3977
Epoch [6/7], Step [160/1201], Loss: 1.0234
Epoch [6/7], Step [170/1201], Loss: 1.1245
Epoch [6/7], Step [180/1201], Loss: 0.9436
Epoch [6/7], Step [190/1201], Loss: 0.8374
Epoch [6/7], Step [200/1201], Loss: 0.7348
Epoch [6/7], Step [210/1201], Loss: 1.1007
Epoch [6/7], Step [220/1201], Loss: 1.0140
Epoch [6/7], Step [230/1201], Loss: 1.1487
Epoch [6/7], Step [240/1201], Loss: 0.9961
Epoch [6/7], Step [250/1201], Loss: 1.2574
Epoch [6/7], Step [260/1201], Loss: 0.8993
Epoch [6/7], Step [270/1201], Loss: 1.2176
Epoch [6/7], Step [280/1201], Loss: 1.2730
Epoch [6/7], Step [290/1201], Loss: 0.7926
Epoch [6/7], Step [300/1201], Loss: 1.2573
Epoch [6/7], Step [310/1201], Loss: 1.2187
Epoch [6/7], Step [320/1201], Loss: 0.6121
Epoch [6/7], Step [330/1201], Loss: 1.4841
Epoch [6/7], Step [340/1201], Loss: 1.2739
Epoch [6/7], Step [350/1201], Loss: 0.9107
Epoch [6/7], Step [360/1201], Loss: 1.5616
Epoch [6/7], Step [370/1201], Loss: 0.8511
Epoch [6/7], Step [380/1201], Loss: 1.0224
Epoch [6/7], Step [390/1201], Loss: 1.3521
Epoch [6/7], Step [400/1201], Loss: 1.2974
Epoch [6/7], Step [410/1201], Loss: 1.6431
Epoch [6/7], Step [420/1201], Loss: 1.1981
Epoch [6/7], Step [430/1201], Loss: 0.9483
Epoch [6/7], Step [440/1201], Loss: 0.8002
Epoch [6/7], Step [450/1201], Loss: 1.1740
Epoch [6/7], Step [460/1201], Loss: 1.0693
Epoch [6/7], Step [470/1201], Loss: 1.2600
Epoch [6/7], Step [480/1201], Loss: 1.2178
Epoch [6/7], Step [490/1201], Loss: 1.1041
Epoch [6/7], Step [500/1201], Loss: 1.1315
Epoch [6/7], Step [510/1201], Loss: 1.0889
Epoch [6/7], Step [520/1201], Loss: 0.9462
Epoch [6/7], Step [530/1201], Loss: 0.8872
Epoch [6/7], Step [540/1201], Loss: 1.2342
Epoch [6/7], Step [550/1201], Loss: 0.9422
Epoch [6/7], Step [560/1201], Loss: 0.9447
Epoch [6/7], Step [570/1201], Loss: 1.0197
Epoch [6/7], Step [580/1201], Loss: 1.0585
Epoch [6/7], Step [590/1201], Loss: 1.1442
Epoch [6/7], Step [600/1201], Loss: 0.9334
Epoch [6/7], Step [610/1201], Loss: 1.1492
Epoch [6/7], Step [620/1201], Loss: 0.8579
Epoch [6/7], Step [630/1201], Loss: 1.4654
Epoch [6/7], Step [640/1201], Loss: 0.8943
Epoch [6/7], Step [650/1201], Loss: 1.1601
Epoch [6/7], Step [660/1201], Loss: 1.2761
Epoch [6/7], Step [670/1201], Loss: 1.2838
Epoch [6/7], Step [680/1201], Loss: 1.0900
Epoch [6/7], Step [690/1201], Loss: 0.9397
Epoch [6/7], Step [700/1201], Loss: 1.1420
Epoch [6/7], Step [710/1201], Loss: 1.1466
Epoch [6/7], Step [720/1201], Loss: 0.8842
Epoch [6/7], Step [730/1201], Loss: 0.9178
Epoch [6/7], Step [740/1201], Loss: 1.3394
Epoch [6/7], Step [750/1201], Loss: 1.1296
Epoch [6/7], Step [760/1201], Loss: 0.8950
Epoch [6/7], Step [770/1201], Loss: 1.1300
Epoch [6/7], Step [780/1201], Loss: 1.2775
Epoch [6/7], Step [790/1201], Loss: 1.3429
Epoch [6/7], Step [800/1201], Loss: 1.0281
Epoch [6/7], Step [810/1201], Loss: 0.9311
Epoch [6/7], Step [820/1201], Loss: 1.1586
Epoch [6/7], Step [830/1201], Loss: 1.2100
Epoch [6/7], Step [840/1201], Loss: 0.9775
Epoch [6/7], Step [850/1201], Loss: 1.3828
Epoch [6/7], Step [860/1201], Loss: 1.1439
Epoch [6/7], Step [870/1201], Loss: 1.2389
Epoch [6/7], Step [880/1201], Loss: 0.9683
Epoch [6/7], Step [890/1201], Loss: 1.4426
Epoch [6/7], Step [900/1201], Loss: 1.0029
Epoch [6/7], Step [910/1201], Loss: 0.8872
Epoch [6/7], Step [920/1201], Loss: 1.0121
Epoch [6/7], Step [930/1201], Loss: 1.2947
Epoch [6/7], Step [940/1201], Loss: 0.8849
Epoch [6/7], Step [950/1201], Loss: 1.2305
Epoch [6/7], Step [960/1201], Loss: 1.0413
Epoch [6/7], Step [970/1201], Loss: 0.9190
Epoch [6/7], Step [980/1201], Loss: 0.9974
Epoch [6/7], Step [990/1201], Loss: 0.9628
Epoch [6/7], Step [1000/1201], Loss: 1.0197
Epoch [6/7], Step [1010/1201], Loss: 0.5731
Epoch [6/7], Step [1020/1201], Loss: 1.1963
Epoch [6/7], Step [1030/1201], Loss: 0.7922
Epoch [6/7], Step [1040/1201], Loss: 1.1133
Epoch [6/7], Step [1050/1201], Loss: 0.8085
Epoch [6/7], Step [1060/1201], Loss: 1.1270
Epoch [6/7], Step [1070/1201], Loss: 0.9692
Epoch [6/7], Step [1080/1201], Loss: 1.3458
Epoch [6/7], Step [1090/1201], Loss: 0.9059
Epoch [6/7], Step [1100/1201], Loss: 1.1714
Epoch [6/7], Step [1110/1201], Loss: 0.9609
Epoch [6/7], Step [1120/1201], Loss: 1.3912
Epoch [6/7], Step [1130/1201], Loss: 0.9499
Epoch [6/7], Step [1140/1201], Loss: 0.7899
Epoch [6/7], Step [1150/1201], Loss: 1.1120
Epoch [6/7], Step [1160/1201], Loss: 1.2501
Epoch [6/7], Step [1170/1201], Loss: 0.8232
Epoch [6/7], Step [1180/1201], Loss: 1.0916
Epoch [6/7], Step [1190/1201], Loss: 1.1314
Epoch [6/7], Step [1200/1201], Loss: 1.0468
Total time for epoch 6/7 = 1396.388958 seconds
The average of the epoch train time so far is 1387.3150798
The stdev of the epoch train time so far is 40.14199388229334
Start validation
Validation accuracy is 26.42433079887512%
Start training
Epoch [7/7], Step [10/1201], Loss: 1.2939
Epoch [7/7], Step [20/1201], Loss: 0.9785
Epoch [7/7], Step [30/1201], Loss: 0.8659
Epoch [7/7], Step [40/1201], Loss: 1.0678
Epoch [7/7], Step [50/1201], Loss: 0.7360
Epoch [7/7], Step [60/1201], Loss: 1.2030
Epoch [7/7], Step [70/1201], Loss: 0.9229
Epoch [7/7], Step [80/1201], Loss: 0.7882
Epoch [7/7], Step [90/1201], Loss: 0.8452
Epoch [7/7], Step [100/1201], Loss: 1.1994
Epoch [7/7], Step [110/1201], Loss: 0.8834
Epoch [7/7], Step [120/1201], Loss: 0.9716
Epoch [7/7], Step [130/1201], Loss: 0.9099
Epoch [7/7], Step [140/1201], Loss: 0.7872
Epoch [7/7], Step [150/1201], Loss: 1.3451
Epoch [7/7], Step [160/1201], Loss: 0.9561
Epoch [7/7], Step [170/1201], Loss: 1.1899
Epoch [7/7], Step [180/1201], Loss: 0.8323
Epoch [7/7], Step [190/1201], Loss: 0.7289
Epoch [7/7], Step [200/1201], Loss: 0.6872
Epoch [7/7], Step [210/1201], Loss: 0.8688
Epoch [7/7], Step [220/1201], Loss: 0.9474
Epoch [7/7], Step [230/1201], Loss: 0.9233
Epoch [7/7], Step [240/1201], Loss: 0.9661
Epoch [7/7], Step [250/1201], Loss: 1.1237
Epoch [7/7], Step [260/1201], Loss: 0.9407
Epoch [7/7], Step [270/1201], Loss: 1.1859
Epoch [7/7], Step [280/1201], Loss: 1.0829
Epoch [7/7], Step [290/1201], Loss: 0.8361
Epoch [7/7], Step [300/1201], Loss: 1.2761
Epoch [7/7], Step [310/1201], Loss: 1.0451
Epoch [7/7], Step [320/1201], Loss: 0.4953
Epoch [7/7], Step [330/1201], Loss: 1.4451
Epoch [7/7], Step [340/1201], Loss: 1.1704
Epoch [7/7], Step [350/1201], Loss: 0.8194
Epoch [7/7], Step [360/1201], Loss: 1.4819
Epoch [7/7], Step [370/1201], Loss: 0.8575
Epoch [7/7], Step [380/1201], Loss: 0.9802
Epoch [7/7], Step [390/1201], Loss: 1.2699
Epoch [7/7], Step [400/1201], Loss: 1.4209
Epoch [7/7], Step [410/1201], Loss: 1.5488
Epoch [7/7], Step [420/1201], Loss: 1.1027
Epoch [7/7], Step [430/1201], Loss: 0.9991
Epoch [7/7], Step [440/1201], Loss: 0.7733
Epoch [7/7], Step [450/1201], Loss: 0.9997
Epoch [7/7], Step [460/1201], Loss: 1.0061
Epoch [7/7], Step [470/1201], Loss: 1.3010
Epoch [7/7], Step [480/1201], Loss: 1.1070
Epoch [7/7], Step [490/1201], Loss: 0.8634
Epoch [7/7], Step [500/1201], Loss: 1.0307
Epoch [7/7], Step [510/1201], Loss: 1.1055
Epoch [7/7], Step [520/1201], Loss: 0.8960
Epoch [7/7], Step [530/1201], Loss: 0.7886
Epoch [7/7], Step [540/1201], Loss: 1.0910
Epoch [7/7], Step [550/1201], Loss: 0.7646
Epoch [7/7], Step [560/1201], Loss: 0.8558
Epoch [7/7], Step [570/1201], Loss: 0.8532
Epoch [7/7], Step [580/1201], Loss: 1.0896
Epoch [7/7], Step [590/1201], Loss: 1.0224
Epoch [7/7], Step [600/1201], Loss: 0.8825
Epoch [7/7], Step [610/1201], Loss: 0.9143
Epoch [7/7], Step [620/1201], Loss: 0.8331
Epoch [7/7], Step [630/1201], Loss: 1.2738
Epoch [7/7], Step [640/1201], Loss: 0.8159
Epoch [7/7], Step [650/1201], Loss: 0.9893
Epoch [7/7], Step [660/1201], Loss: 1.2798
Epoch [7/7], Step [670/1201], Loss: 1.1846
Epoch [7/7], Step [680/1201], Loss: 0.9743
Epoch [7/7], Step [690/1201], Loss: 0.9943
Epoch [7/7], Step [700/1201], Loss: 1.0264
Epoch [7/7], Step [710/1201], Loss: 1.0305
Epoch [7/7], Step [720/1201], Loss: 0.8092
Epoch [7/7], Step [730/1201], Loss: 0.9304
Epoch [7/7], Step [740/1201], Loss: 1.2003
Epoch [7/7], Step [750/1201], Loss: 0.9833
Epoch [7/7], Step [760/1201], Loss: 0.7744
Epoch [7/7], Step [770/1201], Loss: 0.8918
Epoch [7/7], Step [780/1201], Loss: 1.2835
Epoch [7/7], Step [790/1201], Loss: 1.2599
Epoch [7/7], Step [800/1201], Loss: 0.9300
Epoch [7/7], Step [810/1201], Loss: 0.8139
Epoch [7/7], Step [820/1201], Loss: 1.0916
Epoch [7/7], Step [830/1201], Loss: 1.0902
Epoch [7/7], Step [840/1201], Loss: 1.0512
Epoch [7/7], Step [850/1201], Loss: 1.1861
Epoch [7/7], Step [860/1201], Loss: 1.1453
Epoch [7/7], Step [870/1201], Loss: 1.1290
Epoch [7/7], Step [880/1201], Loss: 0.7974
Epoch [7/7], Step [890/1201], Loss: 1.5064
Epoch [7/7], Step [900/1201], Loss: 0.9338
Epoch [7/7], Step [910/1201], Loss: 0.8652
Epoch [7/7], Step [920/1201], Loss: 0.9115
Epoch [7/7], Step [930/1201], Loss: 1.1915
Epoch [7/7], Step [940/1201], Loss: 0.6272
Epoch [7/7], Step [950/1201], Loss: 1.0842
Epoch [7/7], Step [960/1201], Loss: 0.9116
Epoch [7/7], Step [970/1201], Loss: 0.9510
Epoch [7/7], Step [980/1201], Loss: 0.8877
Epoch [7/7], Step [990/1201], Loss: 0.8672
Epoch [7/7], Step [1000/1201], Loss: 0.9826
Epoch [7/7], Step [1010/1201], Loss: 0.5406
Epoch [7/7], Step [1020/1201], Loss: 1.2031
Epoch [7/7], Step [1030/1201], Loss: 0.7913
Epoch [7/7], Step [1040/1201], Loss: 1.0435
Epoch [7/7], Step [1050/1201], Loss: 0.6430
Epoch [7/7], Step [1060/1201], Loss: 0.9604
Epoch [7/7], Step [1070/1201], Loss: 0.7279
Epoch [7/7], Step [1080/1201], Loss: 1.1109
Epoch [7/7], Step [1090/1201], Loss: 1.0191
Epoch [7/7], Step [1100/1201], Loss: 1.0826
Epoch [7/7], Step [1110/1201], Loss: 0.9588
Epoch [7/7], Step [1120/1201], Loss: 1.3630
Epoch [7/7], Step [1130/1201], Loss: 0.8578
Epoch [7/7], Step [1140/1201], Loss: 0.6609
Epoch [7/7], Step [1150/1201], Loss: 1.0215
Epoch [7/7], Step [1160/1201], Loss: 1.2043
Epoch [7/7], Step [1170/1201], Loss: 0.7174
Epoch [7/7], Step [1180/1201], Loss: 1.0098
Epoch [7/7], Step [1190/1201], Loss: 0.9279
Epoch [7/7], Step [1200/1201], Loss: 0.8354
Total time for epoch 7/7 = 1499.526843 seconds
The average of the epoch train time so far is 1406.0170403333332
The stdev of the epoch train time so far is 55.60245527843342
Start validation
Validation accuracy is 25.236954483907926%
