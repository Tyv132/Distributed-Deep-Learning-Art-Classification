The size of the training data set is 76814
Start training
Epoch [1/7], Step [10/1201], Loss: 2.4874
Epoch [1/7], Step [20/1201], Loss: 2.3925
Epoch [1/7], Step [30/1201], Loss: 2.2605
Epoch [1/7], Step [40/1201], Loss: 2.0066
Epoch [1/7], Step [50/1201], Loss: 1.9370
Epoch [1/7], Step [60/1201], Loss: 2.0824
Epoch [1/7], Step [70/1201], Loss: 1.8359
Epoch [1/7], Step [80/1201], Loss: 1.9996
Epoch [1/7], Step [90/1201], Loss: 1.8916
Epoch [1/7], Step [100/1201], Loss: 2.0422
Epoch [1/7], Step [110/1201], Loss: 1.8517
Epoch [1/7], Step [120/1201], Loss: 1.8175
Epoch [1/7], Step [130/1201], Loss: 1.5579
Epoch [1/7], Step [140/1201], Loss: 1.8486
Epoch [1/7], Step [150/1201], Loss: 1.8868
Epoch [1/7], Step [160/1201], Loss: 1.7935
Epoch [1/7], Step [170/1201], Loss: 1.9920
Epoch [1/7], Step [180/1201], Loss: 1.9425
Epoch [1/7], Step [190/1201], Loss: 1.5999
Epoch [1/7], Step [200/1201], Loss: 1.8979
Epoch [1/7], Step [210/1201], Loss: 1.9145
Epoch [1/7], Step [220/1201], Loss: 1.6888
Epoch [1/7], Step [230/1201], Loss: 1.9591
Epoch [1/7], Step [240/1201], Loss: 1.6932
Epoch [1/7], Step [250/1201], Loss: 1.8583
Epoch [1/7], Step [260/1201], Loss: 1.7427
Epoch [1/7], Step [270/1201], Loss: 1.8394
Epoch [1/7], Step [280/1201], Loss: 1.6435
Epoch [1/7], Step [290/1201], Loss: 1.7683
Epoch [1/7], Step [300/1201], Loss: 1.8123
Epoch [1/7], Step [310/1201], Loss: 1.8969
Epoch [1/7], Step [320/1201], Loss: 1.5452
Epoch [1/7], Step [330/1201], Loss: 1.8538
Epoch [1/7], Step [340/1201], Loss: 1.8486
Epoch [1/7], Step [350/1201], Loss: 1.7367
Epoch [1/7], Step [360/1201], Loss: 2.1124
Epoch [1/7], Step [370/1201], Loss: 1.6303
Epoch [1/7], Step [380/1201], Loss: 1.8902
Epoch [1/7], Step [390/1201], Loss: 1.8817
Epoch [1/7], Step [400/1201], Loss: 1.8692
Epoch [1/7], Step [410/1201], Loss: 1.9843
Epoch [1/7], Step [420/1201], Loss: 1.6517
Epoch [1/7], Step [430/1201], Loss: 1.5420
Epoch [1/7], Step [440/1201], Loss: 1.5847
Epoch [1/7], Step [450/1201], Loss: 1.9002
Epoch [1/7], Step [460/1201], Loss: 1.8041
Epoch [1/7], Step [470/1201], Loss: 1.8034
Epoch [1/7], Step [480/1201], Loss: 1.9118
Epoch [1/7], Step [490/1201], Loss: 1.7779
Epoch [1/7], Step [500/1201], Loss: 1.7157
Epoch [1/7], Step [510/1201], Loss: 1.6303
Epoch [1/7], Step [520/1201], Loss: 1.5088
Epoch [1/7], Step [530/1201], Loss: 1.5686
Epoch [1/7], Step [540/1201], Loss: 1.7254
Epoch [1/7], Step [550/1201], Loss: 2.0197
Epoch [1/7], Step [560/1201], Loss: 1.9629
Epoch [1/7], Step [570/1201], Loss: 1.4891
Epoch [1/7], Step [580/1201], Loss: 1.7619
Epoch [1/7], Step [590/1201], Loss: 1.8228
Epoch [1/7], Step [600/1201], Loss: 1.4373
Epoch [1/7], Step [610/1201], Loss: 1.7539
Epoch [1/7], Step [620/1201], Loss: 1.7778
Epoch [1/7], Step [630/1201], Loss: 1.9003
Epoch [1/7], Step [640/1201], Loss: 1.3917
Epoch [1/7], Step [650/1201], Loss: 1.6101
Epoch [1/7], Step [660/1201], Loss: 1.6922
Epoch [1/7], Step [670/1201], Loss: 1.7154
Epoch [1/7], Step [680/1201], Loss: 1.5474
Epoch [1/7], Step [690/1201], Loss: 1.8452
Epoch [1/7], Step [700/1201], Loss: 1.6941
Epoch [1/7], Step [710/1201], Loss: 1.7277
Epoch [1/7], Step [720/1201], Loss: 1.6861
Epoch [1/7], Step [730/1201], Loss: 1.6797
Epoch [1/7], Step [740/1201], Loss: 1.9364
Epoch [1/7], Step [750/1201], Loss: 1.6105
Epoch [1/7], Step [760/1201], Loss: 1.7020
Epoch [1/7], Step [770/1201], Loss: 1.5886
Epoch [1/7], Step [780/1201], Loss: 1.5634
Epoch [1/7], Step [790/1201], Loss: 1.8226
Epoch [1/7], Step [800/1201], Loss: 1.6345
Epoch [1/7], Step [810/1201], Loss: 1.4976
Epoch [1/7], Step [820/1201], Loss: 1.7656
Epoch [1/7], Step [830/1201], Loss: 1.5863
Epoch [1/7], Step [840/1201], Loss: 1.7833
Epoch [1/7], Step [850/1201], Loss: 1.7401
Epoch [1/7], Step [860/1201], Loss: 1.5731
Epoch [1/7], Step [870/1201], Loss: 1.7853
Epoch [1/7], Step [880/1201], Loss: 1.5619
Epoch [1/7], Step [890/1201], Loss: 1.8107
Epoch [1/7], Step [900/1201], Loss: 1.6226
Epoch [1/7], Step [910/1201], Loss: 1.3651
Epoch [1/7], Step [920/1201], Loss: 1.8650
Epoch [1/7], Step [930/1201], Loss: 1.7125
Epoch [1/7], Step [940/1201], Loss: 1.5172
Epoch [1/7], Step [950/1201], Loss: 1.7593
Epoch [1/7], Step [960/1201], Loss: 1.6497
Epoch [1/7], Step [970/1201], Loss: 1.6535
Epoch [1/7], Step [980/1201], Loss: 1.6974
Epoch [1/7], Step [990/1201], Loss: 1.5516
Epoch [1/7], Step [1000/1201], Loss: 1.6889
Epoch [1/7], Step [1010/1201], Loss: 1.4927
Epoch [1/7], Step [1020/1201], Loss: 1.7691
Epoch [1/7], Step [1030/1201], Loss: 1.5038
Epoch [1/7], Step [1040/1201], Loss: 1.4868
Epoch [1/7], Step [1050/1201], Loss: 1.4796
Epoch [1/7], Step [1060/1201], Loss: 1.6427
Epoch [1/7], Step [1070/1201], Loss: 1.6425
Epoch [1/7], Step [1080/1201], Loss: 1.7763
Epoch [1/7], Step [1090/1201], Loss: 1.7202
Epoch [1/7], Step [1100/1201], Loss: 1.7070
Epoch [1/7], Step [1110/1201], Loss: 1.8012
Epoch [1/7], Step [1120/1201], Loss: 1.6757
Epoch [1/7], Step [1130/1201], Loss: 1.6611
Epoch [1/7], Step [1140/1201], Loss: 1.5553
Epoch [1/7], Step [1150/1201], Loss: 1.6263
Epoch [1/7], Step [1160/1201], Loss: 1.6394
Epoch [1/7], Step [1170/1201], Loss: 1.5538
Epoch [1/7], Step [1180/1201], Loss: 1.5864
Epoch [1/7], Step [1190/1201], Loss: 1.4583
Epoch [1/7], Step [1200/1201], Loss: 1.6621
Total time for epoch 1/7 = 1647.876737 seconds
Start validation
Validation accuracy is 45.0786376419123%
Start training
Epoch [2/7], Step [10/1201], Loss: 1.6853
Epoch [2/7], Step [20/1201], Loss: 1.7717
Epoch [2/7], Step [30/1201], Loss: 1.7448
Epoch [2/7], Step [40/1201], Loss: 1.6502
Epoch [2/7], Step [50/1201], Loss: 1.2728
Epoch [2/7], Step [60/1201], Loss: 1.8773
Epoch [2/7], Step [70/1201], Loss: 1.6229
Epoch [2/7], Step [80/1201], Loss: 1.4286
Epoch [2/7], Step [90/1201], Loss: 1.6725
Epoch [2/7], Step [100/1201], Loss: 1.7008
Epoch [2/7], Step [110/1201], Loss: 1.5994
Epoch [2/7], Step [120/1201], Loss: 1.6127
Epoch [2/7], Step [130/1201], Loss: 1.3467
Epoch [2/7], Step [140/1201], Loss: 1.4371
Epoch [2/7], Step [150/1201], Loss: 1.6068
Epoch [2/7], Step [160/1201], Loss: 1.2927
Epoch [2/7], Step [170/1201], Loss: 1.7337
Epoch [2/7], Step [180/1201], Loss: 1.5350
Epoch [2/7], Step [190/1201], Loss: 1.3598
Epoch [2/7], Step [200/1201], Loss: 1.4660
Epoch [2/7], Step [210/1201], Loss: 1.6366
Epoch [2/7], Step [220/1201], Loss: 1.4160
Epoch [2/7], Step [230/1201], Loss: 1.8469
Epoch [2/7], Step [240/1201], Loss: 1.3802
Epoch [2/7], Step [250/1201], Loss: 1.6817
Epoch [2/7], Step [260/1201], Loss: 1.5030
Epoch [2/7], Step [270/1201], Loss: 1.4612
Epoch [2/7], Step [280/1201], Loss: 1.5320
Epoch [2/7], Step [290/1201], Loss: 1.4977
Epoch [2/7], Step [300/1201], Loss: 1.5766
Epoch [2/7], Step [310/1201], Loss: 1.6263
Epoch [2/7], Step [320/1201], Loss: 1.1706
Epoch [2/7], Step [330/1201], Loss: 1.7589
Epoch [2/7], Step [340/1201], Loss: 1.6188
Epoch [2/7], Step [350/1201], Loss: 1.5413
Epoch [2/7], Step [360/1201], Loss: 1.6363
Epoch [2/7], Step [370/1201], Loss: 1.4223
Epoch [2/7], Step [380/1201], Loss: 1.6775
Epoch [2/7], Step [390/1201], Loss: 1.7631
Epoch [2/7], Step [400/1201], Loss: 1.7199
Epoch [2/7], Step [410/1201], Loss: 1.8055
Epoch [2/7], Step [420/1201], Loss: 1.4092
Epoch [2/7], Step [430/1201], Loss: 1.3354
Epoch [2/7], Step [440/1201], Loss: 1.3621
Epoch [2/7], Step [450/1201], Loss: 1.6987
Epoch [2/7], Step [460/1201], Loss: 1.5148
Epoch [2/7], Step [470/1201], Loss: 1.5290
Epoch [2/7], Step [480/1201], Loss: 1.6031
Epoch [2/7], Step [490/1201], Loss: 1.6234
Epoch [2/7], Step [500/1201], Loss: 1.5277
Epoch [2/7], Step [510/1201], Loss: 1.4721
Epoch [2/7], Step [520/1201], Loss: 1.3319
Epoch [2/7], Step [530/1201], Loss: 1.3880
Epoch [2/7], Step [540/1201], Loss: 1.3764
Epoch [2/7], Step [550/1201], Loss: 1.5603
Epoch [2/7], Step [560/1201], Loss: 1.5746
Epoch [2/7], Step [570/1201], Loss: 1.3930
Epoch [2/7], Step [580/1201], Loss: 1.4847
Epoch [2/7], Step [590/1201], Loss: 1.4933
Epoch [2/7], Step [600/1201], Loss: 1.2929
Epoch [2/7], Step [610/1201], Loss: 1.5215
Epoch [2/7], Step [620/1201], Loss: 1.4652
Epoch [2/7], Step [630/1201], Loss: 1.7824
Epoch [2/7], Step [640/1201], Loss: 1.2535
Epoch [2/7], Step [650/1201], Loss: 1.4173
Epoch [2/7], Step [660/1201], Loss: 1.6873
Epoch [2/7], Step [670/1201], Loss: 1.5816
Epoch [2/7], Step [680/1201], Loss: 1.3541
Epoch [2/7], Step [690/1201], Loss: 1.7338
Epoch [2/7], Step [700/1201], Loss: 1.3492
Epoch [2/7], Step [710/1201], Loss: 1.5528
Epoch [2/7], Step [720/1201], Loss: 1.4937
Epoch [2/7], Step [730/1201], Loss: 1.3136
Epoch [2/7], Step [740/1201], Loss: 1.6901
Epoch [2/7], Step [750/1201], Loss: 1.4870
Epoch [2/7], Step [760/1201], Loss: 1.3793
Epoch [2/7], Step [770/1201], Loss: 1.5124
Epoch [2/7], Step [780/1201], Loss: 1.3996
Epoch [2/7], Step [790/1201], Loss: 1.6233
Epoch [2/7], Step [800/1201], Loss: 1.4189
Epoch [2/7], Step [810/1201], Loss: 1.2878
Epoch [2/7], Step [820/1201], Loss: 1.6110
Epoch [2/7], Step [830/1201], Loss: 1.4983
Epoch [2/7], Step [840/1201], Loss: 1.4829
Epoch [2/7], Step [850/1201], Loss: 1.5360
Epoch [2/7], Step [860/1201], Loss: 1.4434
Epoch [2/7], Step [870/1201], Loss: 1.6157
Epoch [2/7], Step [880/1201], Loss: 1.3813
Epoch [2/7], Step [890/1201], Loss: 1.6906
Epoch [2/7], Step [900/1201], Loss: 1.4746
Epoch [2/7], Step [910/1201], Loss: 1.1738
Epoch [2/7], Step [920/1201], Loss: 1.6696
Epoch [2/7], Step [930/1201], Loss: 1.5019
Epoch [2/7], Step [940/1201], Loss: 1.2716
Epoch [2/7], Step [950/1201], Loss: 1.5802
Epoch [2/7], Step [960/1201], Loss: 1.4037
Epoch [2/7], Step [970/1201], Loss: 1.3831
Epoch [2/7], Step [980/1201], Loss: 1.5421
Epoch [2/7], Step [990/1201], Loss: 1.2936
Epoch [2/7], Step [1000/1201], Loss: 1.3903
Epoch [2/7], Step [1010/1201], Loss: 1.3409
Epoch [2/7], Step [1020/1201], Loss: 1.5610
Epoch [2/7], Step [1030/1201], Loss: 1.3214
Epoch [2/7], Step [1040/1201], Loss: 1.2762
Epoch [2/7], Step [1050/1201], Loss: 1.3133
Epoch [2/7], Step [1060/1201], Loss: 1.4350
Epoch [2/7], Step [1070/1201], Loss: 1.5221
Epoch [2/7], Step [1080/1201], Loss: 1.6143
Epoch [2/7], Step [1090/1201], Loss: 1.6472
Epoch [2/7], Step [1100/1201], Loss: 1.6317
Epoch [2/7], Step [1110/1201], Loss: 1.6241
Epoch [2/7], Step [1120/1201], Loss: 1.4819
Epoch [2/7], Step [1130/1201], Loss: 1.3919
Epoch [2/7], Step [1140/1201], Loss: 1.4004
Epoch [2/7], Step [1150/1201], Loss: 1.4271
Epoch [2/7], Step [1160/1201], Loss: 1.5308
Epoch [2/7], Step [1170/1201], Loss: 1.3964
Epoch [2/7], Step [1180/1201], Loss: 1.4641
Epoch [2/7], Step [1190/1201], Loss: 1.3232
Epoch [2/7], Step [1200/1201], Loss: 1.4183
Total time for epoch 2/7 = 1352.645856 seconds
The average of the epoch train time so far is 1352.645856
The stdev of the epoch train time so far is 0.0
Start validation
Validation accuracy is 51.81751900843662%
Start training
Epoch [3/7], Step [10/1201], Loss: 1.5681
Epoch [3/7], Step [20/1201], Loss: 1.5835
Epoch [3/7], Step [30/1201], Loss: 1.4584
Epoch [3/7], Step [40/1201], Loss: 1.3334
Epoch [3/7], Step [50/1201], Loss: 1.0970
Epoch [3/7], Step [60/1201], Loss: 1.7353
Epoch [3/7], Step [70/1201], Loss: 1.4644
Epoch [3/7], Step [80/1201], Loss: 1.3300
Epoch [3/7], Step [90/1201], Loss: 1.4412
Epoch [3/7], Step [100/1201], Loss: 1.5714
Epoch [3/7], Step [110/1201], Loss: 1.5281
Epoch [3/7], Step [120/1201], Loss: 1.4082
Epoch [3/7], Step [130/1201], Loss: 1.1398
Epoch [3/7], Step [140/1201], Loss: 1.2528
Epoch [3/7], Step [150/1201], Loss: 1.4344
Epoch [3/7], Step [160/1201], Loss: 1.1006
Epoch [3/7], Step [170/1201], Loss: 1.5297
Epoch [3/7], Step [180/1201], Loss: 1.3639
Epoch [3/7], Step [190/1201], Loss: 1.1977
Epoch [3/7], Step [200/1201], Loss: 1.2273
Epoch [3/7], Step [210/1201], Loss: 1.3589
Epoch [3/7], Step [220/1201], Loss: 1.2656
Epoch [3/7], Step [230/1201], Loss: 1.5849
Epoch [3/7], Step [240/1201], Loss: 1.2221
Epoch [3/7], Step [250/1201], Loss: 1.4631
Epoch [3/7], Step [260/1201], Loss: 1.3410
Epoch [3/7], Step [270/1201], Loss: 1.3339
Epoch [3/7], Step [280/1201], Loss: 1.3161
Epoch [3/7], Step [290/1201], Loss: 1.2777
Epoch [3/7], Step [300/1201], Loss: 1.3928
Epoch [3/7], Step [310/1201], Loss: 1.5309
Epoch [3/7], Step [320/1201], Loss: 0.9709
Epoch [3/7], Step [330/1201], Loss: 1.7380
Epoch [3/7], Step [340/1201], Loss: 1.4037
Epoch [3/7], Step [350/1201], Loss: 1.3722
Epoch [3/7], Step [360/1201], Loss: 1.4320
Epoch [3/7], Step [370/1201], Loss: 1.2139
Epoch [3/7], Step [380/1201], Loss: 1.4805
Epoch [3/7], Step [390/1201], Loss: 1.5809
Epoch [3/7], Step [400/1201], Loss: 1.5965
Epoch [3/7], Step [410/1201], Loss: 1.6288
Epoch [3/7], Step [420/1201], Loss: 1.3521
Epoch [3/7], Step [430/1201], Loss: 1.1455
Epoch [3/7], Step [440/1201], Loss: 1.2430
Epoch [3/7], Step [450/1201], Loss: 1.6285
Epoch [3/7], Step [460/1201], Loss: 1.3968
Epoch [3/7], Step [470/1201], Loss: 1.3804
Epoch [3/7], Step [480/1201], Loss: 1.4650
Epoch [3/7], Step [490/1201], Loss: 1.4092
Epoch [3/7], Step [500/1201], Loss: 1.4131
Epoch [3/7], Step [510/1201], Loss: 1.3532
Epoch [3/7], Step [520/1201], Loss: 1.1467
Epoch [3/7], Step [530/1201], Loss: 1.2940
Epoch [3/7], Step [540/1201], Loss: 1.2301
Epoch [3/7], Step [550/1201], Loss: 1.2861
Epoch [3/7], Step [560/1201], Loss: 1.5052
Epoch [3/7], Step [570/1201], Loss: 1.2769
Epoch [3/7], Step [580/1201], Loss: 1.2839
Epoch [3/7], Step [590/1201], Loss: 1.2361
Epoch [3/7], Step [600/1201], Loss: 1.2127
Epoch [3/7], Step [610/1201], Loss: 1.3311
Epoch [3/7], Step [620/1201], Loss: 1.3656
Epoch [3/7], Step [630/1201], Loss: 1.6467
Epoch [3/7], Step [640/1201], Loss: 1.1876
Epoch [3/7], Step [650/1201], Loss: 1.3189
Epoch [3/7], Step [660/1201], Loss: 1.4113
Epoch [3/7], Step [670/1201], Loss: 1.4659
Epoch [3/7], Step [680/1201], Loss: 1.1745
Epoch [3/7], Step [690/1201], Loss: 1.4872
Epoch [3/7], Step [700/1201], Loss: 1.2728
Epoch [3/7], Step [710/1201], Loss: 1.3802
Epoch [3/7], Step [720/1201], Loss: 1.4429
Epoch [3/7], Step [730/1201], Loss: 1.0915
Epoch [3/7], Step [740/1201], Loss: 1.4640
Epoch [3/7], Step [750/1201], Loss: 1.3578
Epoch [3/7], Step [760/1201], Loss: 1.1520
Epoch [3/7], Step [770/1201], Loss: 1.3558
Epoch [3/7], Step [780/1201], Loss: 1.3308
Epoch [3/7], Step [790/1201], Loss: 1.4834
Epoch [3/7], Step [800/1201], Loss: 1.3108
Epoch [3/7], Step [810/1201], Loss: 1.2135
Epoch [3/7], Step [820/1201], Loss: 1.3999
Epoch [3/7], Step [830/1201], Loss: 1.3886
Epoch [3/7], Step [840/1201], Loss: 1.3184
Epoch [3/7], Step [850/1201], Loss: 1.4135
Epoch [3/7], Step [860/1201], Loss: 1.2271
Epoch [3/7], Step [870/1201], Loss: 1.4939
Epoch [3/7], Step [880/1201], Loss: 1.2353
Epoch [3/7], Step [890/1201], Loss: 1.6014
Epoch [3/7], Step [900/1201], Loss: 1.3670
Epoch [3/7], Step [910/1201], Loss: 1.0477
Epoch [3/7], Step [920/1201], Loss: 1.5346
Epoch [3/7], Step [930/1201], Loss: 1.4133
Epoch [3/7], Step [940/1201], Loss: 1.1321
Epoch [3/7], Step [950/1201], Loss: 1.6072
Epoch [3/7], Step [960/1201], Loss: 1.3437
Epoch [3/7], Step [970/1201], Loss: 1.2417
Epoch [3/7], Step [980/1201], Loss: 1.3533
Epoch [3/7], Step [990/1201], Loss: 1.2165
Epoch [3/7], Step [1000/1201], Loss: 1.3683
Epoch [3/7], Step [1010/1201], Loss: 1.1974
Epoch [3/7], Step [1020/1201], Loss: 1.3940
Epoch [3/7], Step [1030/1201], Loss: 1.2794
Epoch [3/7], Step [1040/1201], Loss: 1.1111
Epoch [3/7], Step [1050/1201], Loss: 1.1469
Epoch [3/7], Step [1060/1201], Loss: 1.2724
Epoch [3/7], Step [1070/1201], Loss: 1.3245
Epoch [3/7], Step [1080/1201], Loss: 1.4829
Epoch [3/7], Step [1090/1201], Loss: 1.5526
Epoch [3/7], Step [1100/1201], Loss: 1.5066
Epoch [3/7], Step [1110/1201], Loss: 1.4136
Epoch [3/7], Step [1120/1201], Loss: 1.3352
Epoch [3/7], Step [1130/1201], Loss: 1.2983
Epoch [3/7], Step [1140/1201], Loss: 1.2454
Epoch [3/7], Step [1150/1201], Loss: 1.3384
Epoch [3/7], Step [1160/1201], Loss: 1.3619
Epoch [3/7], Step [1170/1201], Loss: 1.1925
Epoch [3/7], Step [1180/1201], Loss: 1.3396
Epoch [3/7], Step [1190/1201], Loss: 1.1944
Epoch [3/7], Step [1200/1201], Loss: 1.3322
Total time for epoch 3/7 = 1325.184146 seconds
The average of the epoch train time so far is 1338.915001
The stdev of the epoch train time so far is 13.73085500000002
Start validation
Validation accuracy is 53.36944068326216%
Start training
Epoch [4/7], Step [10/1201], Loss: 1.4494
Epoch [4/7], Step [20/1201], Loss: 1.3486
Epoch [4/7], Step [30/1201], Loss: 1.3778
Epoch [4/7], Step [40/1201], Loss: 1.1205
Epoch [4/7], Step [50/1201], Loss: 1.0496
Epoch [4/7], Step [60/1201], Loss: 1.5889
Epoch [4/7], Step [70/1201], Loss: 1.3347
Epoch [4/7], Step [80/1201], Loss: 1.2050
Epoch [4/7], Step [90/1201], Loss: 1.2869
Epoch [4/7], Step [100/1201], Loss: 1.4400
Epoch [4/7], Step [110/1201], Loss: 1.4037
Epoch [4/7], Step [120/1201], Loss: 1.2488
Epoch [4/7], Step [130/1201], Loss: 1.0717
Epoch [4/7], Step [140/1201], Loss: 1.1764
Epoch [4/7], Step [150/1201], Loss: 1.3143
Epoch [4/7], Step [160/1201], Loss: 1.0000
Epoch [4/7], Step [170/1201], Loss: 1.3570
Epoch [4/7], Step [180/1201], Loss: 1.2304
Epoch [4/7], Step [190/1201], Loss: 1.0585
Epoch [4/7], Step [200/1201], Loss: 1.0527
Epoch [4/7], Step [210/1201], Loss: 1.2444
Epoch [4/7], Step [220/1201], Loss: 1.2264
Epoch [4/7], Step [230/1201], Loss: 1.4211
Epoch [4/7], Step [240/1201], Loss: 1.1487
Epoch [4/7], Step [250/1201], Loss: 1.3441
Epoch [4/7], Step [260/1201], Loss: 1.2440
Epoch [4/7], Step [270/1201], Loss: 1.2345
Epoch [4/7], Step [280/1201], Loss: 1.2364
Epoch [4/7], Step [290/1201], Loss: 1.2379
Epoch [4/7], Step [300/1201], Loss: 1.2882
Epoch [4/7], Step [310/1201], Loss: 1.4972
Epoch [4/7], Step [320/1201], Loss: 0.9060
Epoch [4/7], Step [330/1201], Loss: 1.6082
Epoch [4/7], Step [340/1201], Loss: 1.2914
Epoch [4/7], Step [350/1201], Loss: 1.3061
Epoch [4/7], Step [360/1201], Loss: 1.3755
Epoch [4/7], Step [370/1201], Loss: 1.0966
Epoch [4/7], Step [380/1201], Loss: 1.3362
Epoch [4/7], Step [390/1201], Loss: 1.3324
Epoch [4/7], Step [400/1201], Loss: 1.4139
Epoch [4/7], Step [410/1201], Loss: 1.6501
Epoch [4/7], Step [420/1201], Loss: 1.2897
Epoch [4/7], Step [430/1201], Loss: 1.0670
Epoch [4/7], Step [440/1201], Loss: 1.1302
Epoch [4/7], Step [450/1201], Loss: 1.5275
Epoch [4/7], Step [460/1201], Loss: 1.3592
Epoch [4/7], Step [470/1201], Loss: 1.4414
Epoch [4/7], Step [480/1201], Loss: 1.2753
Epoch [4/7], Step [490/1201], Loss: 1.3124
Epoch [4/7], Step [500/1201], Loss: 1.2889
Epoch [4/7], Step [510/1201], Loss: 1.2100
Epoch [4/7], Step [520/1201], Loss: 1.0296
Epoch [4/7], Step [530/1201], Loss: 1.2474
Epoch [4/7], Step [540/1201], Loss: 1.2093
Epoch [4/7], Step [550/1201], Loss: 1.2847
Epoch [4/7], Step [560/1201], Loss: 1.4488
Epoch [4/7], Step [570/1201], Loss: 1.1878
Epoch [4/7], Step [580/1201], Loss: 1.2101
Epoch [4/7], Step [590/1201], Loss: 1.0919
Epoch [4/7], Step [600/1201], Loss: 1.1321
Epoch [4/7], Step [610/1201], Loss: 1.2731
Epoch [4/7], Step [620/1201], Loss: 1.2797
Epoch [4/7], Step [630/1201], Loss: 1.5347
Epoch [4/7], Step [640/1201], Loss: 1.1510
Epoch [4/7], Step [650/1201], Loss: 1.2047
Epoch [4/7], Step [660/1201], Loss: 1.2176
Epoch [4/7], Step [670/1201], Loss: 1.3670
Epoch [4/7], Step [680/1201], Loss: 0.9966
Epoch [4/7], Step [690/1201], Loss: 1.4256
Epoch [4/7], Step [700/1201], Loss: 1.0972
Epoch [4/7], Step [710/1201], Loss: 1.2594
Epoch [4/7], Step [720/1201], Loss: 1.3161
Epoch [4/7], Step [730/1201], Loss: 1.0415
Epoch [4/7], Step [740/1201], Loss: 1.3323
Epoch [4/7], Step [750/1201], Loss: 1.3281
Epoch [4/7], Step [760/1201], Loss: 1.1267
Epoch [4/7], Step [770/1201], Loss: 1.2958
Epoch [4/7], Step [780/1201], Loss: 1.2317
Epoch [4/7], Step [790/1201], Loss: 1.3828
Epoch [4/7], Step [800/1201], Loss: 1.2042
Epoch [4/7], Step [810/1201], Loss: 1.1548
Epoch [4/7], Step [820/1201], Loss: 1.2240
Epoch [4/7], Step [830/1201], Loss: 1.2132
Epoch [4/7], Step [840/1201], Loss: 1.1609
Epoch [4/7], Step [850/1201], Loss: 1.3662
Epoch [4/7], Step [860/1201], Loss: 1.1507
Epoch [4/7], Step [870/1201], Loss: 1.4731
Epoch [4/7], Step [880/1201], Loss: 1.1774
Epoch [4/7], Step [890/1201], Loss: 1.5076
Epoch [4/7], Step [900/1201], Loss: 1.2424
Epoch [4/7], Step [910/1201], Loss: 1.0181
Epoch [4/7], Step [920/1201], Loss: 1.4282
Epoch [4/7], Step [930/1201], Loss: 1.3639
Epoch [4/7], Step [940/1201], Loss: 1.0635
Epoch [4/7], Step [950/1201], Loss: 1.4490
Epoch [4/7], Step [960/1201], Loss: 1.2365
Epoch [4/7], Step [970/1201], Loss: 1.1474
Epoch [4/7], Step [980/1201], Loss: 1.2523
Epoch [4/7], Step [990/1201], Loss: 1.1532
Epoch [4/7], Step [1000/1201], Loss: 1.3203
Epoch [4/7], Step [1010/1201], Loss: 1.0603
Epoch [4/7], Step [1020/1201], Loss: 1.3473
Epoch [4/7], Step [1030/1201], Loss: 1.1979
Epoch [4/7], Step [1040/1201], Loss: 1.0480
Epoch [4/7], Step [1050/1201], Loss: 1.0884
Epoch [4/7], Step [1060/1201], Loss: 1.1338
Epoch [4/7], Step [1070/1201], Loss: 1.2021
Epoch [4/7], Step [1080/1201], Loss: 1.4409
Epoch [4/7], Step [1090/1201], Loss: 1.4202
Epoch [4/7], Step [1100/1201], Loss: 1.4009
Epoch [4/7], Step [1110/1201], Loss: 1.2070
Epoch [4/7], Step [1120/1201], Loss: 1.2583
Epoch [4/7], Step [1130/1201], Loss: 1.0946
Epoch [4/7], Step [1140/1201], Loss: 1.2150
Epoch [4/7], Step [1150/1201], Loss: 1.2530
Epoch [4/7], Step [1160/1201], Loss: 1.3149
Epoch [4/7], Step [1170/1201], Loss: 1.0073
Epoch [4/7], Step [1180/1201], Loss: 1.2531
Epoch [4/7], Step [1190/1201], Loss: 1.1768
Epoch [4/7], Step [1200/1201], Loss: 1.2660
Total time for epoch 4/7 = 1323.584246 seconds
The average of the epoch train time so far is 1333.8047493333333
The stdev of the epoch train time so far is 13.338675479497848
Start validation
Validation accuracy is 54.39016769086553%
Start training
Epoch [5/7], Step [10/1201], Loss: 1.3667
Epoch [5/7], Step [20/1201], Loss: 1.2660
Epoch [5/7], Step [30/1201], Loss: 1.2310
Epoch [5/7], Step [40/1201], Loss: 1.0245
Epoch [5/7], Step [50/1201], Loss: 0.9581
Epoch [5/7], Step [60/1201], Loss: 1.4702
Epoch [5/7], Step [70/1201], Loss: 1.2390
Epoch [5/7], Step [80/1201], Loss: 1.1289
Epoch [5/7], Step [90/1201], Loss: 1.2442
Epoch [5/7], Step [100/1201], Loss: 1.3722
Epoch [5/7], Step [110/1201], Loss: 1.2916
Epoch [5/7], Step [120/1201], Loss: 1.1174
Epoch [5/7], Step [130/1201], Loss: 1.0116
Epoch [5/7], Step [140/1201], Loss: 1.0637
Epoch [5/7], Step [150/1201], Loss: 1.2881
Epoch [5/7], Step [160/1201], Loss: 0.9681
Epoch [5/7], Step [170/1201], Loss: 1.2947
Epoch [5/7], Step [180/1201], Loss: 1.1097
Epoch [5/7], Step [190/1201], Loss: 1.0042
Epoch [5/7], Step [200/1201], Loss: 0.9382
Epoch [5/7], Step [210/1201], Loss: 1.1278
Epoch [5/7], Step [220/1201], Loss: 1.1666
Epoch [5/7], Step [230/1201], Loss: 1.2692
Epoch [5/7], Step [240/1201], Loss: 1.1024
Epoch [5/7], Step [250/1201], Loss: 1.1978
Epoch [5/7], Step [260/1201], Loss: 1.0728
Epoch [5/7], Step [270/1201], Loss: 1.1302
Epoch [5/7], Step [280/1201], Loss: 1.1253
Epoch [5/7], Step [290/1201], Loss: 1.1300
Epoch [5/7], Step [300/1201], Loss: 1.2495
Epoch [5/7], Step [310/1201], Loss: 1.4166
Epoch [5/7], Step [320/1201], Loss: 0.8781
Epoch [5/7], Step [330/1201], Loss: 1.5112
Epoch [5/7], Step [340/1201], Loss: 1.2092
Epoch [5/7], Step [350/1201], Loss: 1.2442
Epoch [5/7], Step [360/1201], Loss: 1.3434
Epoch [5/7], Step [370/1201], Loss: 1.0272
Epoch [5/7], Step [380/1201], Loss: 1.2987
Epoch [5/7], Step [390/1201], Loss: 1.1726
Epoch [5/7], Step [400/1201], Loss: 1.3377
Epoch [5/7], Step [410/1201], Loss: 1.5304
Epoch [5/7], Step [420/1201], Loss: 1.1760
Epoch [5/7], Step [430/1201], Loss: 0.9931
Epoch [5/7], Step [440/1201], Loss: 1.0139
Epoch [5/7], Step [450/1201], Loss: 1.2996
Epoch [5/7], Step [460/1201], Loss: 1.3128
Epoch [5/7], Step [470/1201], Loss: 1.3333
Epoch [5/7], Step [480/1201], Loss: 1.1898
Epoch [5/7], Step [490/1201], Loss: 1.1532
Epoch [5/7], Step [500/1201], Loss: 1.1878
Epoch [5/7], Step [510/1201], Loss: 1.1746
Epoch [5/7], Step [520/1201], Loss: 0.9943
Epoch [5/7], Step [530/1201], Loss: 1.1771
Epoch [5/7], Step [540/1201], Loss: 1.1524
Epoch [5/7], Step [550/1201], Loss: 1.2002
Epoch [5/7], Step [560/1201], Loss: 1.4015
Epoch [5/7], Step [570/1201], Loss: 1.1157
Epoch [5/7], Step [580/1201], Loss: 1.1253
Epoch [5/7], Step [590/1201], Loss: 1.0603
Epoch [5/7], Step [600/1201], Loss: 1.0900
Epoch [5/7], Step [610/1201], Loss: 1.1326
Epoch [5/7], Step [620/1201], Loss: 1.1137
Epoch [5/7], Step [630/1201], Loss: 1.4620
Epoch [5/7], Step [640/1201], Loss: 1.1289
Epoch [5/7], Step [650/1201], Loss: 1.1136
Epoch [5/7], Step [660/1201], Loss: 1.0986
Epoch [5/7], Step [670/1201], Loss: 1.2214
Epoch [5/7], Step [680/1201], Loss: 0.9117
Epoch [5/7], Step [690/1201], Loss: 1.3890
Epoch [5/7], Step [700/1201], Loss: 0.9610
Epoch [5/7], Step [710/1201], Loss: 1.1245
Epoch [5/7], Step [720/1201], Loss: 1.2566
Epoch [5/7], Step [730/1201], Loss: 0.9893
Epoch [5/7], Step [740/1201], Loss: 1.2320
Epoch [5/7], Step [750/1201], Loss: 1.2632
Epoch [5/7], Step [760/1201], Loss: 1.0269
Epoch [5/7], Step [770/1201], Loss: 1.2689
Epoch [5/7], Step [780/1201], Loss: 1.1529
Epoch [5/7], Step [790/1201], Loss: 1.3610
Epoch [5/7], Step [800/1201], Loss: 1.1364
Epoch [5/7], Step [810/1201], Loss: 1.0926
Epoch [5/7], Step [820/1201], Loss: 1.1356
Epoch [5/7], Step [830/1201], Loss: 1.0620
Epoch [5/7], Step [840/1201], Loss: 1.0872
Epoch [5/7], Step [850/1201], Loss: 1.3021
Epoch [5/7], Step [860/1201], Loss: 1.0758
Epoch [5/7], Step [870/1201], Loss: 1.4855
Epoch [5/7], Step [880/1201], Loss: 1.1150
Epoch [5/7], Step [890/1201], Loss: 1.4641
Epoch [5/7], Step [900/1201], Loss: 1.1600
Epoch [5/7], Step [910/1201], Loss: 1.0129
Epoch [5/7], Step [920/1201], Loss: 1.3461
Epoch [5/7], Step [930/1201], Loss: 1.2421
Epoch [5/7], Step [940/1201], Loss: 0.9940
Epoch [5/7], Step [950/1201], Loss: 1.3717
Epoch [5/7], Step [960/1201], Loss: 1.0725
Epoch [5/7], Step [970/1201], Loss: 1.0871
Epoch [5/7], Step [980/1201], Loss: 1.1355
Epoch [5/7], Step [990/1201], Loss: 1.1143
Epoch [5/7], Step [1000/1201], Loss: 1.2538
Epoch [5/7], Step [1010/1201], Loss: 0.9702
Epoch [5/7], Step [1020/1201], Loss: 1.2744
Epoch [5/7], Step [1030/1201], Loss: 1.0715
Epoch [5/7], Step [1040/1201], Loss: 0.9929
Epoch [5/7], Step [1050/1201], Loss: 0.9589
Epoch [5/7], Step [1060/1201], Loss: 1.1109
Epoch [5/7], Step [1070/1201], Loss: 1.1309
Epoch [5/7], Step [1080/1201], Loss: 1.2738
Epoch [5/7], Step [1090/1201], Loss: 1.2963
Epoch [5/7], Step [1100/1201], Loss: 1.2513
Epoch [5/7], Step [1110/1201], Loss: 1.0845
Epoch [5/7], Step [1120/1201], Loss: 1.1743
Epoch [5/7], Step [1130/1201], Loss: 1.0725
Epoch [5/7], Step [1140/1201], Loss: 1.1076
Epoch [5/7], Step [1150/1201], Loss: 1.0887
Epoch [5/7], Step [1160/1201], Loss: 1.2381
Epoch [5/7], Step [1170/1201], Loss: 0.9176
Epoch [5/7], Step [1180/1201], Loss: 1.1466
Epoch [5/7], Step [1190/1201], Loss: 1.1829
Epoch [5/7], Step [1200/1201], Loss: 1.1802
Total time for epoch 5/7 = 1329.59461 seconds
The average of the epoch train time so far is 1332.7522145
The stdev of the epoch train time so far is 11.694600736521869
Start validation
Validation accuracy is 57.25445266118113%
Start training
Epoch [6/7], Step [10/1201], Loss: 1.2296
Epoch [6/7], Step [20/1201], Loss: 1.1608
Epoch [6/7], Step [30/1201], Loss: 1.0847
Epoch [6/7], Step [40/1201], Loss: 0.9347
Epoch [6/7], Step [50/1201], Loss: 0.9646
Epoch [6/7], Step [60/1201], Loss: 1.3215
Epoch [6/7], Step [70/1201], Loss: 1.1946
Epoch [6/7], Step [80/1201], Loss: 1.0455
Epoch [6/7], Step [90/1201], Loss: 1.0695
Epoch [6/7], Step [100/1201], Loss: 1.2779
Epoch [6/7], Step [110/1201], Loss: 1.1857
Epoch [6/7], Step [120/1201], Loss: 1.1046
Epoch [6/7], Step [130/1201], Loss: 1.0252
Epoch [6/7], Step [140/1201], Loss: 0.9222
Epoch [6/7], Step [150/1201], Loss: 1.2224
Epoch [6/7], Step [160/1201], Loss: 0.8323
Epoch [6/7], Step [170/1201], Loss: 1.1966
Epoch [6/7], Step [180/1201], Loss: 0.9211
Epoch [6/7], Step [190/1201], Loss: 0.9149
Epoch [6/7], Step [200/1201], Loss: 0.9092
Epoch [6/7], Step [210/1201], Loss: 1.0060
Epoch [6/7], Step [220/1201], Loss: 1.0715
Epoch [6/7], Step [230/1201], Loss: 1.1531
Epoch [6/7], Step [240/1201], Loss: 1.0326
Epoch [6/7], Step [250/1201], Loss: 1.1503
Epoch [6/7], Step [260/1201], Loss: 1.0444
Epoch [6/7], Step [270/1201], Loss: 1.0697
Epoch [6/7], Step [280/1201], Loss: 0.9660
Epoch [6/7], Step [290/1201], Loss: 1.0490
Epoch [6/7], Step [300/1201], Loss: 1.1539
Epoch [6/7], Step [310/1201], Loss: 1.3293
Epoch [6/7], Step [320/1201], Loss: 0.7181
Epoch [6/7], Step [330/1201], Loss: 1.5087
Epoch [6/7], Step [340/1201], Loss: 1.1223
Epoch [6/7], Step [350/1201], Loss: 1.1395
Epoch [6/7], Step [360/1201], Loss: 1.2182
Epoch [6/7], Step [370/1201], Loss: 0.9558
Epoch [6/7], Step [380/1201], Loss: 1.1194
Epoch [6/7], Step [390/1201], Loss: 1.1632
Epoch [6/7], Step [400/1201], Loss: 1.2786
Epoch [6/7], Step [410/1201], Loss: 1.4081
Epoch [6/7], Step [420/1201], Loss: 1.1584
Epoch [6/7], Step [430/1201], Loss: 1.0208
Epoch [6/7], Step [440/1201], Loss: 0.9388
Epoch [6/7], Step [450/1201], Loss: 1.1002
Epoch [6/7], Step [460/1201], Loss: 1.2098
Epoch [6/7], Step [470/1201], Loss: 1.2355
Epoch [6/7], Step [480/1201], Loss: 1.1116
Epoch [6/7], Step [490/1201], Loss: 1.0463
Epoch [6/7], Step [500/1201], Loss: 1.0972
Epoch [6/7], Step [510/1201], Loss: 1.0628
Epoch [6/7], Step [520/1201], Loss: 0.9562
Epoch [6/7], Step [530/1201], Loss: 1.1143
Epoch [6/7], Step [540/1201], Loss: 1.0987
Epoch [6/7], Step [550/1201], Loss: 1.1572
Epoch [6/7], Step [560/1201], Loss: 1.3603
Epoch [6/7], Step [570/1201], Loss: 1.0545
Epoch [6/7], Step [580/1201], Loss: 1.1062
Epoch [6/7], Step [590/1201], Loss: 0.9343
Epoch [6/7], Step [600/1201], Loss: 1.0128
Epoch [6/7], Step [610/1201], Loss: 1.1332
Epoch [6/7], Step [620/1201], Loss: 0.9845
Epoch [6/7], Step [630/1201], Loss: 1.3572
Epoch [6/7], Step [640/1201], Loss: 1.0302
Epoch [6/7], Step [650/1201], Loss: 0.9871
Epoch [6/7], Step [660/1201], Loss: 1.0547
Epoch [6/7], Step [670/1201], Loss: 1.1690
Epoch [6/7], Step [680/1201], Loss: 0.7818
Epoch [6/7], Step [690/1201], Loss: 1.2587
Epoch [6/7], Step [700/1201], Loss: 0.9190
Epoch [6/7], Step [710/1201], Loss: 1.0482
Epoch [6/7], Step [720/1201], Loss: 1.1194
Epoch [6/7], Step [730/1201], Loss: 0.9552
Epoch [6/7], Step [740/1201], Loss: 1.1818
Epoch [6/7], Step [750/1201], Loss: 1.2017
Epoch [6/7], Step [760/1201], Loss: 1.0054
Epoch [6/7], Step [770/1201], Loss: 1.1313
Epoch [6/7], Step [780/1201], Loss: 1.0654
Epoch [6/7], Step [790/1201], Loss: 1.2431
Epoch [6/7], Step [800/1201], Loss: 1.0505
Epoch [6/7], Step [810/1201], Loss: 1.0484
Epoch [6/7], Step [820/1201], Loss: 1.0524
Epoch [6/7], Step [830/1201], Loss: 0.9835
Epoch [6/7], Step [840/1201], Loss: 1.0618
Epoch [6/7], Step [850/1201], Loss: 1.0894
Epoch [6/7], Step [860/1201], Loss: 0.9818
Epoch [6/7], Step [870/1201], Loss: 1.3745
Epoch [6/7], Step [880/1201], Loss: 1.0371
Epoch [6/7], Step [890/1201], Loss: 1.4338
Epoch [6/7], Step [900/1201], Loss: 1.1387
Epoch [6/7], Step [910/1201], Loss: 0.9110
Epoch [6/7], Step [920/1201], Loss: 1.0630
Epoch [6/7], Step [930/1201], Loss: 1.2034
Epoch [6/7], Step [940/1201], Loss: 0.8403
Epoch [6/7], Step [950/1201], Loss: 1.2267
Epoch [6/7], Step [960/1201], Loss: 0.9796
Epoch [6/7], Step [970/1201], Loss: 0.9554
Epoch [6/7], Step [980/1201], Loss: 1.0366
Epoch [6/7], Step [990/1201], Loss: 1.1059
Epoch [6/7], Step [1000/1201], Loss: 1.1880
Epoch [6/7], Step [1010/1201], Loss: 0.9421
Epoch [6/7], Step [1020/1201], Loss: 1.1216
Epoch [6/7], Step [1030/1201], Loss: 0.9875
Epoch [6/7], Step [1040/1201], Loss: 0.9635
Epoch [6/7], Step [1050/1201], Loss: 0.8989
Epoch [6/7], Step [1060/1201], Loss: 0.9842
Epoch [6/7], Step [1070/1201], Loss: 1.0017
Epoch [6/7], Step [1080/1201], Loss: 1.2132
Epoch [6/7], Step [1090/1201], Loss: 1.2206
Epoch [6/7], Step [1100/1201], Loss: 1.1233
Epoch [6/7], Step [1110/1201], Loss: 1.0216
Epoch [6/7], Step [1120/1201], Loss: 1.0916
Epoch [6/7], Step [1130/1201], Loss: 0.9254
Epoch [6/7], Step [1140/1201], Loss: 1.0059
Epoch [6/7], Step [1150/1201], Loss: 1.0624
Epoch [6/7], Step [1160/1201], Loss: 1.1164
Epoch [6/7], Step [1170/1201], Loss: 0.7902
Epoch [6/7], Step [1180/1201], Loss: 0.9590
Epoch [6/7], Step [1190/1201], Loss: 1.0142
Epoch [6/7], Step [1200/1201], Loss: 1.0767
Total time for epoch 6/7 = 1353.664776 seconds
The average of the epoch train time so far is 1336.9347268000001
The stdev of the epoch train time so far is 13.393453089772319
Start validation
Validation accuracy is 57.75440058327258%
Start training
Epoch [7/7], Step [10/1201], Loss: 1.0948
Epoch [7/7], Step [20/1201], Loss: 1.1012
Epoch [7/7], Step [30/1201], Loss: 0.9424
Epoch [7/7], Step [40/1201], Loss: 0.9247
Epoch [7/7], Step [50/1201], Loss: 0.9113
Epoch [7/7], Step [60/1201], Loss: 1.1562
Epoch [7/7], Step [70/1201], Loss: 1.0764
Epoch [7/7], Step [80/1201], Loss: 1.0042
Epoch [7/7], Step [90/1201], Loss: 1.0279
Epoch [7/7], Step [100/1201], Loss: 1.1640
Epoch [7/7], Step [110/1201], Loss: 1.0400
Epoch [7/7], Step [120/1201], Loss: 0.9828
Epoch [7/7], Step [130/1201], Loss: 0.8895
Epoch [7/7], Step [140/1201], Loss: 0.8719
Epoch [7/7], Step [150/1201], Loss: 1.1431
Epoch [7/7], Step [160/1201], Loss: 0.7150
Epoch [7/7], Step [170/1201], Loss: 1.1730
Epoch [7/7], Step [180/1201], Loss: 0.8384
Epoch [7/7], Step [190/1201], Loss: 0.8785
Epoch [7/7], Step [200/1201], Loss: 0.7623
Epoch [7/7], Step [210/1201], Loss: 0.8731
Epoch [7/7], Step [220/1201], Loss: 1.0216
Epoch [7/7], Step [230/1201], Loss: 1.0960
Epoch [7/7], Step [240/1201], Loss: 0.9928
Epoch [7/7], Step [250/1201], Loss: 1.0842
Epoch [7/7], Step [260/1201], Loss: 0.9249
Epoch [7/7], Step [270/1201], Loss: 1.0057
Epoch [7/7], Step [280/1201], Loss: 0.9178
Epoch [7/7], Step [290/1201], Loss: 0.9611
Epoch [7/7], Step [300/1201], Loss: 0.9952
Epoch [7/7], Step [310/1201], Loss: 1.1989
Epoch [7/7], Step [320/1201], Loss: 0.6095
Epoch [7/7], Step [330/1201], Loss: 1.3987
Epoch [7/7], Step [340/1201], Loss: 1.1040
Epoch [7/7], Step [350/1201], Loss: 1.0888
Epoch [7/7], Step [360/1201], Loss: 1.0776
Epoch [7/7], Step [370/1201], Loss: 0.8127
Epoch [7/7], Step [380/1201], Loss: 0.9741
Epoch [7/7], Step [390/1201], Loss: 1.0690
Epoch [7/7], Step [400/1201], Loss: 1.2089
Epoch [7/7], Step [410/1201], Loss: 1.1365
Epoch [7/7], Step [420/1201], Loss: 1.0231
Epoch [7/7], Step [430/1201], Loss: 0.9400
Epoch [7/7], Step [440/1201], Loss: 0.9046
Epoch [7/7], Step [450/1201], Loss: 1.0772
Epoch [7/7], Step [460/1201], Loss: 1.0974
Epoch [7/7], Step [470/1201], Loss: 1.0708
Epoch [7/7], Step [480/1201], Loss: 1.0367
Epoch [7/7], Step [490/1201], Loss: 0.9558
Epoch [7/7], Step [500/1201], Loss: 1.0832
Epoch [7/7], Step [510/1201], Loss: 0.8825
Epoch [7/7], Step [520/1201], Loss: 0.8530
Epoch [7/7], Step [530/1201], Loss: 1.0308
Epoch [7/7], Step [540/1201], Loss: 0.9912
Epoch [7/7], Step [550/1201], Loss: 1.0911
Epoch [7/7], Step [560/1201], Loss: 1.2177
Epoch [7/7], Step [570/1201], Loss: 0.9518
Epoch [7/7], Step [580/1201], Loss: 1.0468
Epoch [7/7], Step [590/1201], Loss: 0.9344
Epoch [7/7], Step [600/1201], Loss: 0.8656
Epoch [7/7], Step [610/1201], Loss: 0.9741
Epoch [7/7], Step [620/1201], Loss: 0.9201
Epoch [7/7], Step [630/1201], Loss: 1.2814
Epoch [7/7], Step [640/1201], Loss: 0.9020
Epoch [7/7], Step [650/1201], Loss: 0.9361
Epoch [7/7], Step [660/1201], Loss: 0.9371
Epoch [7/7], Step [670/1201], Loss: 1.1240
Epoch [7/7], Step [680/1201], Loss: 0.7251
Epoch [7/7], Step [690/1201], Loss: 1.2147
Epoch [7/7], Step [700/1201], Loss: 0.8338
Epoch [7/7], Step [710/1201], Loss: 0.9460
Epoch [7/7], Step [720/1201], Loss: 1.0873
Epoch [7/7], Step [730/1201], Loss: 0.9446
Epoch [7/7], Step [740/1201], Loss: 1.1016
Epoch [7/7], Step [750/1201], Loss: 1.1567
Epoch [7/7], Step [760/1201], Loss: 0.9491
Epoch [7/7], Step [770/1201], Loss: 1.0547
Epoch [7/7], Step [780/1201], Loss: 0.9226
Epoch [7/7], Step [790/1201], Loss: 1.0479
Epoch [7/7], Step [800/1201], Loss: 0.8969
Epoch [7/7], Step [810/1201], Loss: 0.9092
Epoch [7/7], Step [820/1201], Loss: 0.9390
Epoch [7/7], Step [830/1201], Loss: 0.8773
Epoch [7/7], Step [840/1201], Loss: 0.9475
Epoch [7/7], Step [850/1201], Loss: 1.0374
Epoch [7/7], Step [860/1201], Loss: 0.9377
Epoch [7/7], Step [870/1201], Loss: 1.2488
Epoch [7/7], Step [880/1201], Loss: 0.9575
Epoch [7/7], Step [890/1201], Loss: 1.2512
Epoch [7/7], Step [900/1201], Loss: 1.0135
Epoch [7/7], Step [910/1201], Loss: 0.8872
Epoch [7/7], Step [920/1201], Loss: 0.9959
Epoch [7/7], Step [930/1201], Loss: 1.0901
Epoch [7/7], Step [940/1201], Loss: 0.7338
Epoch [7/7], Step [950/1201], Loss: 1.1702
Epoch [7/7], Step [960/1201], Loss: 0.9113
Epoch [7/7], Step [970/1201], Loss: 0.8226
Epoch [7/7], Step [980/1201], Loss: 0.9923
Epoch [7/7], Step [990/1201], Loss: 1.0375
Epoch [7/7], Step [1000/1201], Loss: 1.0143
Epoch [7/7], Step [1010/1201], Loss: 0.8733
Epoch [7/7], Step [1020/1201], Loss: 1.0543
Epoch [7/7], Step [1030/1201], Loss: 0.9551
Epoch [7/7], Step [1040/1201], Loss: 0.8936
Epoch [7/7], Step [1050/1201], Loss: 0.8206
Epoch [7/7], Step [1060/1201], Loss: 0.8766
Epoch [7/7], Step [1070/1201], Loss: 0.9502
Epoch [7/7], Step [1080/1201], Loss: 1.0887
Epoch [7/7], Step [1090/1201], Loss: 1.0839
Epoch [7/7], Step [1100/1201], Loss: 0.9627
Epoch [7/7], Step [1110/1201], Loss: 0.8983
Epoch [7/7], Step [1120/1201], Loss: 0.9547
Epoch [7/7], Step [1130/1201], Loss: 0.8522
Epoch [7/7], Step [1140/1201], Loss: 1.0566
Epoch [7/7], Step [1150/1201], Loss: 0.9684
Epoch [7/7], Step [1160/1201], Loss: 1.0443
Epoch [7/7], Step [1170/1201], Loss: 0.7631
Epoch [7/7], Step [1180/1201], Loss: 0.9329
Epoch [7/7], Step [1190/1201], Loss: 0.9795
Epoch [7/7], Step [1200/1201], Loss: 1.0195
Total time for epoch 7/7 = 1447.290943 seconds
The average of the epoch train time so far is 1355.3274295
The stdev of the epoch train time so far is 42.906231689303716
Start validation
Validation accuracy is 56.40037496094157%
